<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Ruby&#39;s Blog</title>
    <link>https://rubychen0611.github.io/</link>
    
    <atom:link href="https://rubychen0611.github.io/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>自爱兼爱，善感而不多愁。</description>
    <pubDate>Sun, 23 Aug 2020 02:46:28 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>【论文笔记】DeepImportance</title>
      <link>https://rubychen0611.github.io/2020/08/22/DeepImportance/</link>
      <guid>https://rubychen0611.github.io/2020/08/22/DeepImportance/</guid>
      <pubDate>Sat, 22 Aug 2020 07:03:46 GMT</pubDate>
      
      <description>&lt;p&gt;原文：Importance-Driven Deep Learning System Testing （ICSE’20)&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>原文：Importance-Driven Deep Learning System Testing （ICSE’20)  <a id="more"></a></p><p>代码地址：<a href="https://github.com/DeepImportance/deepimportance_code_release">https://github.com/DeepImportance/deepimportance_code_release</a></p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>提出了一种重要性驱动的覆盖标准，首先从训练集和预训练后的DNN模型中分析出重要神经元，然后将重要神经元的激活值聚类，计算测试集对重要神经元激活值簇的组合的覆盖比例，用于评价测试集的<font color="red">语义多样性</font>。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>作者认为前人提出的覆盖标准（如DeepXplore和DeepGauge）：</p><ul><li>这些标准只是神经元(或神经元区域)的集合，它们的激活值符合一定的条件。通过只关注这些受约束的神经元属性而忽略整体DL系统行为，<font color="red">测试集和决策之间的因果关系是无信息性的。</font><ul><li>一个神经元可能有助于增强对其他类的信心，而不是正确的类，这是无法区分的。</li></ul></li><li>这些标准的实例化依赖于<font color="red">用户自定义的条件</font>(所选择神经元的区域、取值上限)，这些条件可能不能充分地表示DL系统的实际行为。</li><li>这些标准不能有效提供<font color="red">单个测试输入的贡献</font>。</li></ul><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="/2020/08/22/DeepImportance/Fig1.png" alt="Fig1"></p><p>步骤：</p><p>1、分析重要神经元</p><p>2、重要神经元激活值聚类</p><p>3、评价测试集的重要神经元覆盖率</p><h3 id="重要神经元分析"><a href="#重要神经元分析" class="headerlink" title="重要神经元分析"></a>重要神经元分析</h3><ul><li><p>逐层相关性传播算法（layer-wise relevance propagation）：</p><ul><li><p>全连接层中：每个神经元的相关性由下一层所有神经元的相关性计算得出：<font color="red">（分母为什么是$\sum i$ ??)</font></p><script type="math/tex; mode=display">R_{ij}= \sum _{k} \frac{ \phi (x,n_{ij})w_{ijk}}{ \sum _{i} \phi (x,n_{ij})w_{ijk}+ \epsilon }R_{i+1,k}</script><ul><li>相关性与激活值成正比：激活值越高的神经元相关性贡献越大</li><li>相关性与连接权重$w_{ijk}$成正比：通过更重要的连接，会产生更多的相关性</li></ul></li></ul></li><li><p>重要性计算算法</p><p><img src="/2020/08/22/DeepImportance/Fig2.png" alt="Fig2" style="zoom:70%;"></p><ul><li>第5行：通过前向传播获得最后一层输出值（softmax之前的值）</li><li>6-8行：反向传播计算相关性</li><li>第10行：分析函数分析所有输入的所有神经元的相关性得分，并根据优先级标准(例如，累积相关性，标准化相关性)对它们进行优先级排序（实验中我们使用累积相关性）</li><li>第11行：返回最重要的m个神经元</li></ul></li><li><p>相关性分析</p><ul><li>使用相关性来识别最重要的神经元是我们的方法的一个关键成分。基于最近<font color="red">DL系统可解释性的研究</font>，其目标是识别负责预测的输入部分，深度重要性的目标是识别最具影响力的神经元;这些是高风险的神经元，应该进行彻底的测试。尽管超出了这项工作的范围，我们也强调<strong>其他可解释性驱动技术</strong>可以用于鉴定最重要的神经元</li><li>与敏感性分析有很大区别：敏感性分析关注的是什么使<strong>已标记</strong>的样本(例如，一只狗)更多或更少地被归类为<strong>目标标签</strong>，而相关性分析研究的是什么使样本被归类为该标签。敏感度分数并不能真正解释为什么样本以某种方式被预测，而是解释输出在<font color="red">输入空间</font>的哪个方向最敏感<font color="red">（输入空间而不是神经元）</font>。相反，相关性得分表明哪些神经元/输入对分类是关键的。</li></ul></li></ul><h3 id="重要神经元聚类"><a href="#重要神经元聚类" class="headerlink" title="重要神经元聚类"></a>重要神经元聚类</h3><ul><li>动机<ul><li>由于每个神经元负责感知输入区域内的特定特征，我们认为，对于具有类似特征的输入，那些重要神经元的激活值集中在它们的<font color="red">值域中的特定区域</font>。非正式地说，这些区域形成一种模式，捕获DL系统中最具影响力的神经元的活动。</li><li>与DeepGauge中的KMNC相比较，我们的方法生成的簇对应每个神经元不同的<strong>语义特征</strong>。</li></ul></li><li>算法<ul><li>$k$-means聚类：我们将每个重要神经元的激活值划分为组(簇)，使同一组内的激活值与同一组内的其他激活值更相似，而与其他组内的激活值不相似。</li><li>如何确定$k$值？<ul><li>我们使用Silhouette index自动识别一种神经元特异性的最优策略，用于聚类每个重要神经元的激活值。（略）</li></ul></li></ul></li></ul><h3 id="基于重要性的覆盖率（IDC）"><a href="#基于重要性的覆盖率（IDC）" class="headerlink" title="基于重要性的覆盖率（IDC）"></a>基于重要性的覆盖率（IDC）</h3><p>评价测试集对于重要神经元的激活值簇的组合的覆盖情况。</p><p>重要神经元激活值簇的组合定义为：</p><script type="math/tex; mode=display">INCC= \prod _{n \in D_{m}} \left\{ CENTROID( \Phi _{n}^{i})|\forall 1 \leqslant i \leqslant | \Phi _{n}| \right\}</script><p>IDC定义为：(即有多少组组合被覆盖)</p><p>$IDC(Y)= \frac{| \left\{ INCC(j)|\exists y \in Y:\forall V_{n}^{i} \in INCC(j) \bullet \min d( \phi (y,n),V_{n}^{i} \right\} |}{|INCC|}$</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集和模型"><a href="#数据集和模型" class="headerlink" title="数据集和模型"></a>数据集和模型</h3><p><img src="/2020/08/22/DeepImportance/Fig3.png" alt="Fig3" style="zoom:60%;"></p><h3 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h3><ul><li>神经元覆盖率NC：阈值为0.75</li><li>TKNC：$k=3$</li><li>KMNC：$k=1000$</li><li>NBC、SNAC：训练集激活值的最值为上下界</li><li>DSC、LSC：上界为2、2000，bucket数为1000</li><li>选择重要性神经元的层：<strong>倒数第二层</strong></li><li>$m \in \{6,8,10,12\}$</li><li>最大运行时间：3h</li><li>对抗样本生成方法：FGSM、BIM、JSMA、C&amp;W</li></ul><h3 id="RQ1-重要性-神经元重要性分析能识别出最重要的神经元吗"><a href="#RQ1-重要性-神经元重要性分析能识别出最重要的神经元吗" class="headerlink" title="RQ1(重要性):神经元重要性分析能识别出最重要的神经元吗?"></a>RQ1(重要性):神经元重要性分析能识别出最重要的神经元吗?</h3><ul><li>实验方法：使用[11]中可解释性工作的方法识别出前10%的重要像素，扰动这些像素的值（超过0.5则设为0，不足0.5设为1），测量随机选取的神经元和DeepImportance选取的重要神经元的值的改动情况，如下表所示。</li><li>实验结果：DeepImportance选取出的重要神经元变动幅度更大，说明这些神经元对给定输入的相关像素的变化更敏感。</li></ul><p><img src="/2020/08/22/DeepImportance/Fig4.png" alt="Fig4" style="zoom:30%;"></p><h3 id="RQ2-多样性-DeepImportance能有助于选择多样化的测试集吗"><a href="#RQ2-多样性-DeepImportance能有助于选择多样化的测试集吗" class="headerlink" title="RQ2(多样性):DeepImportance能有助于选择多样化的测试集吗?"></a>RQ2(多样性):DeepImportance能有助于选择多样化的测试集吗?</h3><ul><li><p>实验方法：</p><ul><li><p>$U_{DI}$: 在所有图片前2%重要像素（识别方法同上）上增加高斯白噪声扰动（MNIST 15个像素，CIFAR-10 20个像素，driving 200个像素）</p></li><li><p>$U_S$:和$U_{DI}$一样，但像素位置是随机选的</p><p><img src="/2020/08/22/DeepImportance/Fig5.png" alt="Fig5" style="zoom:60%;"></p></li></ul></li><li><p>实验结果</p><p><img src="/2020/08/22/DeepImportance/Fig6.png" alt="Fig6"></p><ul><li>对于IDC标准：$U_{O+DI}$在所有实验配置上覆盖率最高。表明IDC对决策任务中重要的输入特性更为敏感，而不是随机选择的特性。</li><li>随着$m$增加，IDC覆盖率逐渐降低，</li></ul></li></ul><h3 id="RQ3-有效性-DeepImportance在识别DL系统中的错误行为时的效果"><a href="#RQ3-有效性-DeepImportance在识别DL系统中的错误行为时的效果" class="headerlink" title="RQ3(有效性):DeepImportance在识别DL系统中的错误行为时的效果?"></a>RQ3(有效性):DeepImportance在识别DL系统中的错误行为时的效果?</h3><ul><li>生成对抗样本<ul><li>FGSM、BIM、JSMA、C&amp;W和RQ1中的白噪音数据集（$U_S$:方差为0.3,准确率97.4%）</li></ul></li></ul><p><img src="/2020/08/22/DeepImportance/Fig7.png" alt="Fig7" style="zoom:40%;"></p><ul><li>实验结果：<ul><li>与原始测试集$U_O$相比，所有DL系统的增强测试集的IDC覆盖率结果都有相当大的增长。</li><li>与高斯类噪声输入$U_{O+S}$相比，在含有对抗样本的测试集中，这种增长更为显著。</li><li>IDC对敌对的输入很敏感，并且在输入与之前遇到的输入在语义上不同的测试集中能够有效地检测出错误行为。</li></ul></li></ul><h3 id="RQ4-相关性-DeepImportance与现有覆盖率标准的相关性"><a href="#RQ4-相关性-DeepImportance与现有覆盖率标准的相关性" class="headerlink" title="RQ4(相关性):DeepImportance与现有覆盖率标准的相关性?"></a>RQ4(相关性):DeepImportance与现有覆盖率标准的相关性?</h3><ul><li>如上图。IDC显示了与DL系统其他覆盖标准相似的行为;因此，二者之间存在正相关关系。</li></ul><h3 id="RQ5-层灵敏度-特定神经元层的选择如何影响DeepImportance的行为"><a href="#RQ5-层灵敏度-特定神经元层的选择如何影响DeepImportance的行为" class="headerlink" title="RQ5(层灵敏度):特定神经元层的选择如何影响DeepImportance的行为?"></a>RQ5(层灵敏度):特定神经元层的选择如何影响DeepImportance的行为?</h3><p><img src="/2020/08/22/DeepImportance/Fig8.png" alt="Fig8" style="zoom:60%;"></p><ul><li>我们观察到，当分析在较深的层而不是浅层执行时，IDC值会增加</li><li>IDC对具有不同语义输入的测试集更敏感($U_{O+DI}$)</li><li>目标层的选择会影响IDC的结果。由于倒数第二层负责理解语义上重要的高级特性，我们认为它是使用IDC评估测试集充分性的合适选择。</li></ul><h2 id="可控制参数-变量"><a href="#可控制参数-变量" class="headerlink" title="可控制参数/变量"></a>可控制参数/变量</h2><ul><li>$m$：选择的重要神经元个数，决定了测试的粒度，$m$越大组合数爆炸式增长</li><li>选择重要性神经元的层</li></ul><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>这篇文章所采用的重要性神经元识别方法非原创（来自《On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation》），DeepCheck也用过类似的方法；覆盖率计算方法也很简单（组合测试）。亮点在于将DNN测试覆盖标准与语义可解释性相结合，这可能是未来的一个趋势。</p>]]></content:encoded>
      
      
      <category domain="https://rubychen0611.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</category>
      
      
      <category domain="https://rubychen0611.github.io/tags/DNN%E6%B5%8B%E8%AF%95/">DNN测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%B5%8B%E8%AF%95%E6%A0%87%E5%87%86/">测试标准</category>
      
      
      <comments>https://rubychen0611.github.io/2020/08/22/DeepImportance/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Google Girl Hackathon Season VI赛后感</title>
      <link>https://rubychen0611.github.io/2020/08/21/Google-Girl-Hackathon/</link>
      <guid>https://rubychen0611.github.io/2020/08/21/Google-Girl-Hackathon/</guid>
      <pubDate>Fri, 21 Aug 2020 11:24:36 GMT</pubDate>
      
      <description>&lt;p&gt;今年的Google女生黑客马拉松比赛历时四个月终于在上个周末结束啦。我们队伍获得项目第一名（1/198）和最受欢迎奖（所有决赛参赛者投票投出来的），这个结果其实在意料之外也在意料之中，不过归根结底还是很不容易（要知道去年我可是连简历关都没过= = |||），今天来总结一下赛后感。&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>今年的Google女生黑客马拉松比赛历时四个月终于在上个周末结束啦。我们队伍获得项目第一名（1/198）和最受欢迎奖（所有决赛参赛者投票投出来的），这个结果其实在意料之外也在意料之中，不过归根结底还是很不容易（要知道去年我可是连简历关都没过= = |||），今天来总结一下赛后感。<a id="more"></a></p><p>今年由于疫情，比赛改成了线上举办，赛题为设计并开发出一款对疫情有帮助的产品，形式不限，必须用到至少一个Google的工具。初赛交设计方案，复赛交代码、文档和视频Demo，决赛线上展示和答辩。（比赛主页：<a href="https://events.withgoogle.com/google-girl-hackathon-cn/#content">https://events.withgoogle.com/google-girl-hackathon-cn/#content</a> ）</p><p>我们提交的产品是一款疫情国际新闻浏览APP，但与一般新闻APP不同的是，我们的APP将不同媒体报道的同一新闻（或相关新闻）聚集成一个个新闻组，对新闻组里每条新闻组进行情绪分析后，将包含情绪分差较大的新闻组排到前面展示给用户。核心思想是情绪差异较大的文章往往意味着观点上的差异也较大，从中我们可以发现媒体偏见，尽管每篇文章本身并非完全客观的，但通过对比不同观点的文章，希望用户从中培养理性和独立思考的习惯，摒弃偏见和成见，增进互相理解、齐心抗疫。</p><p>这是我们的演示视频（更新后的版本）：</p><iframe width="560" height="315" src="https://www.youtube.com/embed/8401Arz0FHs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p>APP前端用的是Google的Flutter，这个是第一次写，以前只写过IOS和一点点安卓，不过上手还是蛮快的，现成的模板有很多。下面是APP后端运行的一个原理流程图↓，后端由Python编写，新闻爬虫部分使用的是GitHub上的一个开源工具NewsPaper3k，能够自动从指定的新闻网站链接爬取新闻（标题、内容、图片等，共50多个英文网站），先保存在本地的MySQL数据库里。接下来我们将每篇文章用TF-IDF算法进行编码，然后使用基于密聚类度的DBSCAN算法将相关新闻聚类，选择合适参数下聚类效果还是不错的，其余没被聚成类的文章则被丢弃。然后用Vader工具对新闻组里的文章进行情绪分析，Vader使用的是基于词典的无监督情绪分析算法，根据标题和正文的综合得分给出每篇文章的情绪分数，Vader是跟其他两个工具（包括TextBlob和另外一个忘了）进行人工比较效果后选择的，效果还是可以的，比如我们观察到跟朝鲜相关的新闻，几乎都是一水儿的超级负面情绪，（评委曾问我如何评价效果，这个因为没有标注我说只能人工检查，或者说我们的效果依赖于使用工具的效果，暂时没想到更好的检查方法）。最后我们将包含情绪分差较大的新闻组排在前面，并上传到LeanCloud后端云数据库中（其实本来想用的是Google的Firebase，但网实在不太好，而且Firebase竟然没有关于在Flutter上如何使用的文档，震惊）。前端的设备直接和LeanCloud交互获得数据，以及完成一些辅助功能如评论、收藏、搜索等。</p><p><img src="/2020/08/21/Google-Girl-Hackathon/overview.png" alt="overview" style="zoom:30%;"></p><p>总结一下我觉得此次能得奖的关键之处吧（开始不要脸的自夸）：</p><p>首先我们的立足点足够大、解决的问题足够广泛，评委在颁奖时强调了我们产品注重多样性的特点与Google致力的目标一致。这个idea其实是我日常刷完各种公众号、豆瓣、知乎之后半夜躺在床上有感而发想出来的，视频和PPT里引用的谭德塞的话是某天知乎热榜标题上看到的，所以动机其实也是带着真情实感的。。虽然受到过队友质疑反对但还是据理力争做下来了。尽管情绪分析的方法很简单常见，但我们的最终目标其实是发现不同观点的文章，情绪分析只是我们挑选的一个容易下手的角度，还有更多复杂的观点分析方法可以运用在我们的产品中。</p><p>高中语文课学过的课文我一篇也记不起来了，但语文老师有两句话我一直记得，一句是他在我们文理分科前建议我们学理科，因为科技可以改变世界，但记住一定要做一个“有情怀的理科生”。另一句是他语重心长地和我们说人应该常怀“悲悯“。当时之所以印象深刻，可能是因为这两个词都曾被他大大地写在了黑板上，但那时候却并不明白个中意味，直到最近几年才常想起才觉得常想常新。我想今天拿到这个比赛结果也算没有辜负他的话。我始终觉得，作为科技行业从业者，开发出为人们提供日常生活便利和娱乐的产品当然好，但更高的要求是看到人世间的苦难并尝试为其做出一点改变，或是对人们的思想和精神领域带来正面的影响。</p><p>第二也要感激这一年的研究生生活，从写论文、看论文、讲论文的过程中不知不觉培养了自己英文学术写作和演示的能力。逐渐发现作品本身质量固然重要，但如何讲好一个完整的故事有时候更加重要，一个专业、逻辑清晰完整、美观大方的展示会给产品大大加分，反之搞不好会给本来不错的产品扣印象分，那就得不偿失了。</p>]]></content:encoded>
      
      
      <category domain="https://rubychen0611.github.io/categories/%E6%9D%82%E8%AE%B0%E9%9A%8F%E6%84%9F/">杂记随感</category>
      
      
      <category domain="https://rubychen0611.github.io/tags/%E6%AF%94%E8%B5%9B/">比赛</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E7%A7%BB%E5%8A%A8%E5%BC%80%E5%8F%91/">移动开发</category>
      
      
      <comments>https://rubychen0611.github.io/2020/08/21/Google-Girl-Hackathon/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【论文笔记】DeepHunter</title>
      <link>https://rubychen0611.github.io/2020/08/20/DeepHunter/</link>
      <guid>https://rubychen0611.github.io/2020/08/20/DeepHunter/</guid>
      <pubDate>Thu, 20 Aug 2020 08:56:28 GMT</pubDate>
      
      <description>&lt;p&gt;原文：DeepHunter: A Coverage-Guided Fuzz Testing Framework for Deep Neural Networks （ISSTA’19)&lt;/p&gt;
&lt;p&gt;Coverage-guided Fuzzing for Feedforward Neural Networks (ASE’19)&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>原文：DeepHunter: A Coverage-Guided Fuzz Testing Framework for Deep Neural Networks （ISSTA’19)</p><p>Coverage-guided Fuzzing for Feedforward Neural Networks (ASE’19)  <a id="more"></a></p><p>代码地址：<a href="https://bitbucket.org/xiaofeixie/deephunter/src/master/">https://bitbucket.org/xiaofeixie/deephunter/src/master/</a></p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><ul><li><p>输入和可控变量：</p><ul><li>初始种子集合</li><li>种子选择策略：<ul><li>①随机</li><li>②根据新鲜程度选择</li><li>③平衡新鲜和多样<ul><li>带有参数$\gamma$、$p_{min}$</li></ul></li></ul></li><li>蜕变变换方法<ul><li>8种图像变换方法<ul><li>4种像素级别变换（像素值改变）：反相、亮度、模糊、噪声</li><li>4种仿射变换（移动像素位置）：平移、缩放、裁剪、旋转</li></ul></li><li>约束策略中的$\alpha$、$\beta$参数</li></ul></li><li>K：常数，变换次数</li><li>覆盖率标准：5种（NC、KMNC、NBC、SNAC、TKNC）标准及其附带参数</li></ul></li><li><p>输出：1、能最大化覆盖率的预测正确的样例 2、预测错误的样例</p><p><img src="/2020/08/20/DeepHunter/1.png" alt="1" style="zoom:60%;"></p><h3 id="保持蜕变变换语义不变的策略"><a href="#保持蜕变变换语义不变的策略" class="headerlink" title="保持蜕变变换语义不变的策略"></a>保持蜕变变换语义不变的策略</h3><ul><li><p>8种图像变换方法</p><ul><li>4种像素级别变换（像素值改变）：反相、亮度、模糊、噪声</li><li>4种仿射变换（移动像素位置）：平移、缩放、裁剪、旋转</li></ul></li><li><p>假设一次变换语义不变（参数合适的情况下）。</p></li><li><font color="red">策略：只允许一次仿射变换，像素变换可以使用多次，但要进行约束</font><ul><li><p>约束条件：像素变换应满足f(s,s’)的条件，$L_0$表示发生变化的像素数目的最大值，$L_\infty$表示像素值变化的最大值。即：要么发生变化的像素数不多，要么变化的像素数多，但像素值变化都不大。平衡二者</p><p><img src="/2020/08/20/DeepHunter/4.png" alt="4" style="zoom:70%;"></p></li></ul></li><li><p>reference image：一张图像在经过一系列变换后（最多一次仿射变换），计算f(s,s’)。如果没有仿射变换的话，参考图像为原图；否则参考图像为中间经过一次仿射变换后的图像。</p><ul><li><p>如果有仿射变换，则$L_0$、$L_\infty$计算方法如下</p><p><img src="/2020/08/20/DeepHunter/3.png" alt="3" style="zoom:60%;"></p></li></ul></li><li><p>种子选择策略（三种）</p><ul><li><p>传统程序和TensorFuzz、DeepTest：用栈，选最新生成的种子</p></li><li><p>uniform：随机选一个种子</p></li><li><p>新策略Probability：平衡新鲜性和多样性，种子s被选择的概率：</p><p><img src="/2020/08/20/DeepHunter/4.png" alt="4" style="zoom:60%;"></p></li></ul></li></ul></li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集和DNN模型"><a href="#数据集和DNN模型" class="headerlink" title="数据集和DNN模型"></a>数据集和DNN模型</h3><p><img src="/2020/08/20/DeepHunter/5.png" alt="5" style="zoom:60%;"></p><h3 id="共同参数设置"><a href="#共同参数设置" class="headerlink" title="共同参数设置"></a>共同参数设置</h3><ul><li><p>NC阈值：0.75（与DeepXplore相同）</p></li><li><p>KMNC的K=1000</p></li><li><p>SNAC、NBC、TKNC与DeepGauge相同设置</p></li><li><p>TRY_NUM=50</p></li><li><p>$\gamma=20$，$p_{min}=0.5$ </p></li><li>$K=20$</li></ul><h3 id="RQ1（蜕变变换）：从人类角度看，不同的变换及约束策略对生成和原图片相同语义的新图效果如何？"><a href="#RQ1（蜕变变换）：从人类角度看，不同的变换及约束策略对生成和原图片相同语义的新图效果如何？" class="headerlink" title="RQ1（蜕变变换）：从人类角度看，不同的变换及约束策略对生成和原图片相同语义的新图效果如何？"></a>RQ1（蜕变变换）：从人类角度看，不同的变换及约束策略对生成和原图片相同语义的新图效果如何？</h3><ul><li><p>实验设计</p><ul><li><p>比较三种变换及约束策略：<font color="red">（仅约束策略还是连带变换策略？没说清楚）</font></p><ul><li><p>DeepHunter：用f(s,s’)限制，设置$\alpha=0.02，\beta=0.2$</p></li><li><p>TensorFuzz： 用 $L_\infty=0.4$限制</p></li><li><p>DeepTest： 用保守的参数限制(原文的MSE限制仅限回归任务，所以没用)</p></li></ul></li><li><p>每个数据集随机选择30个种子输入生成5000张图片，3个数据集*3种生成方法*生成5000张图片=共45000张图片</p></li><li><p>9个测试者每人看一组图片：如果生成的图片与原图分类不同、或是没有语义则被标记为invalid。</p></li></ul></li><li><p>实验结果</p><p><img src="/2020/08/20/DeepHunter/6.png" alt="10"></p><ul><li>对三种策略：CIFAR-10数据集的无效率普遍高于其他两个数据集<ul><li>原因：CIFAR-10分辨率较低，即使是DNN能识别的有效输入，对于人类常难以识别</li></ul></li><li>即使DeepTest的参数设置很保守，但是仍生成了很多无效输入；TensorFuzz经过L∞限制后无效输入少了很多</li><li>结论：DeepHunter的蜕变变换策略有效减少了生成无效图片的数量</li></ul></li></ul><h3 id="RQ2（覆盖率）：CGF是否在DNN测试领域仍能有效提升覆盖率？不同覆盖标准下，不同的seed生成策略对提升覆盖率效果如何？"><a href="#RQ2（覆盖率）：CGF是否在DNN测试领域仍能有效提升覆盖率？不同覆盖标准下，不同的seed生成策略对提升覆盖率效果如何？" class="headerlink" title="RQ2（覆盖率）：CGF是否在DNN测试领域仍能有效提升覆盖率？不同覆盖标准下，不同的seed生成策略对提升覆盖率效果如何？"></a>RQ2（覆盖率）：CGF是否在DNN测试领域仍能有效提升覆盖率？不同覆盖标准下，不同的seed生成策略对提升覆盖率效果如何？</h3><ul><li><p>RQ2&amp;3 实验设计</p><ul><li>比较5种seed选取策略<ul><li>Random testing (RT)without coverage guidance. 作为baseline，随机测试，无覆盖率作为向导</li><li>DeepHunter+Uniform (DH+UF) ：使用不同的覆盖率标准作为向导，随机选择种子顺序</li><li>DeepHunter+Probability (DH+Prob)：使用不同的覆盖率标准作为向导，用概率策略选择种子顺序</li><li>DeepTest seed selection strategy with coverage guidance：选最新的；如果一个种子生成的所有新样例都不能提升覆盖率，则该种子被移出队列。队列可能变空。</li><li>TensorFuzz seed selection strategy with coverage guidance：随机选一个种子和队列最后的5个种子，再从中随机选一个</li></ul></li><li><p>21个fuzzers：5 个覆盖准则 × 4 个seed选择策略 + 1 RT with no coverage guidance，使用的模型为MNIST和CIFAR-10的四个模型；每个fuzzer运行10遍取平均</p></li><li><p>初始种子1000个：被所有模型都正确分类的测试数据</p></li><li>每个fuzzer迭代次数相同（5000次），使用的蜕变变换策略相同<font color="red">（是什么？）</font></li></ul></li><li><p>实验结果</p><p><img src="/2020/08/20/DeepHunter/7.png" alt="7" style="zoom:60%;"></p></li><li><p>结论</p><ul><li><p>尽管基本结构与传统程序很不同，CGF方法与随机测试相比较还是能有效最大化DNN程序的覆盖率</p></li><li><p>与传统软件的fuzzer优先选择最新生成的用例作为种子不同，DNN testing中种子选择的优先策略（多样性）也很重要</p></li><li><p>不同覆盖率标准提升的难易程度不同，KMNC, TKNC, 和 NC提升较容易。NBC and SNAC关注corner cases，本身初始seed覆盖率就极低，提升较难</p></li></ul></li></ul><h3 id="RQ3（错误检测）：现有的覆盖标准在引导错误检测的效果上有何不同？使用不同seed选取标准检测错误的效果有何不同？不同seed选取标准检测出的错误行为有何不同？"><a href="#RQ3（错误检测）：现有的覆盖标准在引导错误检测的效果上有何不同？使用不同seed选取标准检测错误的效果有何不同？不同seed选取标准检测出的错误行为有何不同？" class="headerlink" title="RQ3（错误检测）：现有的覆盖标准在引导错误检测的效果上有何不同？使用不同seed选取标准检测错误的效果有何不同？不同seed选取标准检测出的错误行为有何不同？"></a>RQ3（错误检测）：现有的覆盖标准在引导错误检测的效果上有何不同？使用不同seed选取标准检测错误的效果有何不同？不同seed选取标准检测出的错误行为有何不同？</h3><ul><li><p>实验结果</p><ul><li><p>检测错误数量</p><p><img src="/2020/08/20/DeepHunter/8.png" alt="8" style="zoom:60%;"></p><ul><li>DH+Prob和DH+UF检测错误数目多于另外三种策略，且模型较小时二者类似，模型较大时DF+Prob更优</li><li>KMNC在检测错误数目上少于其他4个覆盖率标准，因为cover更简单；但DH+Prob的表现还是优于其他策略</li><li>在最后的seed queue中，易于cover的覆盖率标准剩余的seed更多</li></ul></li><li><p>检测出的错误的多样性</p><p><img src="/2020/08/20/DeepHunter/9.png" alt="9" style="zoom:60%;"></p><ul><li>定义从同一个seed变换产生的错误属于同一类别，共1000类</li><li>DH+Prob和DH+UF能检测出更多类的错误，DeepTest和TensorFuzz检测出的错误甚至有的比RT还少，因为这二者都倾向于选择最新的seed</li><li>RT：过于随机，难以发现corner cases</li><li>选最新的seed：能发现Corner cases，但类别过于单一</li></ul></li></ul></li></ul><h3 id="RQ4（平台迁移）：DeepHunter是否适用于平台迁移过程中DNN量化引入的具体缺陷检测"><a href="#RQ4（平台迁移）：DeepHunter是否适用于平台迁移过程中DNN量化引入的具体缺陷检测" class="headerlink" title="RQ4（平台迁移）：DeepHunter是否适用于平台迁移过程中DNN量化引入的具体缺陷检测?"></a>RQ4（平台迁移）：DeepHunter是否适用于平台迁移过程中DNN量化引入的具体缺陷检测?</h3><ul><li><p>实验设计</p><ul><li><p>每个数据集选择一个模型，原模型都是32bit</p></li><li><p>3种量化方式</p><ul><li><p>随机选10%的权重缩减：32比特-&gt;16比特</p></li><li><p>随机选50%的权重缩减：32比特-&gt;16比特</p></li><li><p>所有权重缩减：32比特-&gt;16比特</p></li></ul></li><li><p>对前两种量化方式（10%和50%的量化模型）：sample10次得到10个模型，每个模型运行5遍取均值</p></li><li><p>为每个原始模型分配10小时生成图片，重复每种配置5次并平均结果</p></li></ul></li><li><p>实验结果</p><p><img src="/2020/08/20/DeepHunter/10.png" alt="10" style="zoom:60%;"></p><ul><li>corner相关的覆盖率标准更易发现量化错误</li><li>DNN模型越大，发现的错误越多</li><li>QR率越大，错误越多</li></ul></li></ul>]]></content:encoded>
      
      
      <category domain="https://rubychen0611.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</category>
      
      
      <category domain="https://rubychen0611.github.io/tags/DNN%E6%B5%8B%E8%AF%95/">DNN测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95/">模糊测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%B5%8B%E8%AF%95%E8%BE%93%E5%85%A5%E7%94%9F%E6%88%90/">测试输入生成</category>
      
      
      <comments>https://rubychen0611.github.io/2020/08/20/DeepHunter/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【论文笔记】DeepTest</title>
      <link>https://rubychen0611.github.io/2020/08/20/DeepTest/</link>
      <guid>https://rubychen0611.github.io/2020/08/20/DeepTest/</guid>
      <pubDate>Thu, 20 Aug 2020 08:56:17 GMT</pubDate>
      
      <description>&lt;p&gt;原文：DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars  (ICSE’18)&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>原文：DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars  (ICSE’18)  <a id="more"></a></p><p>代码地址：<a href="https://github.com/ARiSE-Lab/deepTest">https://github.com/ARiSE-Lab/deepTest</a></p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><ul><li><p>神经元覆盖率计算方式：卷积层与DeepXplore有所不同，<font color="red">输出特征图的平均值与激活阈值做比较</font></p></li><li><p>9种图像变换方式：</p><ul><li>线性变换：<ul><li>亮度：所有像素值加/减一个常数</li><li>对比度：所有像素值乘以一个常数</li></ul></li><li>仿射变换：平移、缩放、水平修剪、旋转 （模拟摄像头的移动）</li><li>卷积变换：<ul><li>模糊（4种：averaging, Gaussian, median, and bilateral）</li><li>雾雨（Adobe Photoshop）</li></ul></li></ul></li><li><p>覆盖率引导的贪心搜索变换叠加算法</p><p><img src="/2020/08/20/DeepTest/Fig1.png" alt="Fig1" style="zoom:75%;"></p><ul><li><p>蜕变关系约束</p><ul><li><p>对一张图片，蜕变后的预测角度$\theta_{ti}$与真实标记$θ_i$之间的差距应小于原始数据集平均MSE的λ倍</p><script type="math/tex; mode=display">(\theta_i-\theta_{ti}) \leq \lambda MSE_{orig}</script></li></ul></li></ul></li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集及模型"><a href="#数据集及模型" class="headerlink" title="数据集及模型"></a>数据集及模型</h3><ul><li><p>数据集：Driving</p></li><li><p>模型：Udacity比赛排名第2、3、6的模型Rambo、Chauffeur、Epoch</p><p><img src="/2020/08/20/DeepTest/Fig2.png" alt="Fig2" style="zoom:80%;"></p></li></ul><h3 id="可控制参数或变量"><a href="#可控制参数或变量" class="headerlink" title="可控制参数或变量"></a>可控制参数或变量</h3><ul><li><p>maxFailedTries: 变换叠加时最大尝试次数</p></li><li><p>各变换参数及可选范围：</p><p><img src="/2020/08/20/DeepTest/Fig3.png" alt="Fig3" style="zoom:60%;"></p></li><li><p>$\lambda$: 控制蜕变关系约束</p></li><li><p>$\epsilon$：控制变换约束大小</p></li><li><p>神经元激活值</p></li></ul><h3 id="实验1：不同输入输出对是否覆盖不同神经元"><a href="#实验1：不同输入输出对是否覆盖不同神经元" class="headerlink" title="实验1：不同输入输出对是否覆盖不同神经元"></a>实验1：不同输入输出对是否覆盖不同神经元</h3><ul><li><p>实验方法：检查不同模型覆盖率与驾驶方向的Spearman相关性、覆盖率与驾驶角度的Wilcoxon非参数检验结果。（<font color="red">该实验设计是否合理？覆盖率增加，应对应的是输入或输出种类增加而非角度增大？？）</font></p></li><li><p>实验结果</p><ul><li>随着神经元覆盖率的增加，转向角度增加，反之亦然。即不同输出对应不同的神经元，神经元覆盖率可以很好地近似估计输入输出对的多样性。<font color="red">（相关系数结果并不明显？）</font></li><li>神经元覆盖率随导向方向的变化具有统计学意义($p&lt;2.2∗10^{−16}$时) ，有些子模型比其他子模型更负责改变方向。</li><li>总结：对于不同的输入输出对，神经元的覆盖范围很不同。因此，神经覆盖定向(NDG)测试策略可以帮助发现corner样本。</li></ul></li></ul><p><img src="/2020/08/20/DeepTest/Fig4.png" alt="Fig4" style="zoom:80%;"></p><h3 id="实验2：不同图像变换是否激活不同神经元"><a href="#实验2：不同图像变换是否激活不同神经元" class="headerlink" title="实验2：不同图像变换是否激活不同神经元"></a>实验2：不同图像变换是否激活不同神经元</h3><ul><li><p>实验2-1：从测试集随机选择1000张图片，对每张图片分别做7种变换（blur, brightness, contrast, rotation, scale, shear, and translation）以及尝试变换的多种参数，得到共70000张生成图片。在各个模型上运行这些图片，记录神经元激活情况。对任意两种变换的组合（如模糊vs旋转，旋转vs平移等等），设激活神经元集合分别为N1、N2，测量二者的差异大小（Jaccard距离）</p><ul><li>结果：（左图）：除了Chauffeur_LTSM模型之外，不同的变换激活的神经元有较大区别</li></ul></li><li><p>实验2-2：七种变换依次叠加在图片上，查看覆盖率提升情况</p><ul><li>结果（右图）：叠加每种变换后神经元覆盖率都增加了，<font color="red">说明每种变换都能激活不同神经元。（覆盖率提升是因为变换种类增多还是离原图距离越来越远？）</font></li></ul></li></ul><p><img src="/2020/08/20/DeepTest/Fig5.png" alt="Fig5" style="zoom:80%;"></p><ul><li><p>实验2-3：单个变换触发神经元的比例分布情况及平均神经元增加百分比情况</p><ul><li><p>结果：不同的图像变换以不同程度增加神经元的覆盖率。<font color="red">（下表的两行没看懂）</font></p><p><img src="/2020/08/20/DeepTest/Fig6.png" alt="Fig6" style="zoom:80%;"></p></li></ul></li></ul><h3 id="实验3：结合不同变换是否能进一步提升神经元覆盖率"><a href="#实验3：结合不同变换是否能进一步提升神经元覆盖率" class="headerlink" title="实验3：结合不同变换是否能进一步提升神经元覆盖率"></a>实验3：结合不同变换是否能进一步提升神经元覆盖率</h3><ul><li><p>实验方法：</p><ul><li>Baseline组：原始的100个种子输入</li><li>累积变换组：在100个种子输入上叠加7种变换的10种参数组合，得到7000张生成图片。</li><li>覆盖率引导的贪心搜索组：仅生成了254、221、864张图片（对应三个模型）</li></ul></li><li><p>实验结果：通过系统地结合不同的图像变换，神经元的覆盖率比原始种子图像的覆盖率提高了约100%。</p><p><img src="/2020/08/20/DeepTest/Fig7.png" alt="Fig7" style="zoom:80%;"></p></li></ul><h3 id="实验4：使用蜕变关系是否能检测到错误行为"><a href="#实验4：使用蜕变关系是否能检测到错误行为" class="headerlink" title="实验4：使用蜕变关系是否能检测到错误行为"></a>实验4：使用蜕变关系是否能检测到错误行为</h3><ul><li><p>实验4-1：生成图片与原图片和真实标记之间的偏差情况</p><p><img src="/2020/08/20/DeepTest/Fig8.png" alt="Fig8" style="zoom:60%;"></p><ul><li>结果：生成图片集合的MSE为0.41，原图片集合为0.035。因此生成的图片更有可能触发错误行为</li></ul></li><li><p>实验4-2：生成错误图片数量</p><ul><li><p>实验方法：</p><ul><li><p><strong>约束：为了防止图片变化过大或误报出现（如旋转后旋转角度应跟着变化），使用的变换（除了雾、雨）及其参数必须满足：</strong></p><p><script type="math/tex">|MSE(trans,param)-MSE_{org}|\leq \epsilon</script> （<font color="red">计算MSE用到了人工标记的oracle，在实际测试没有oracle时怎么办？</font>)</p></li></ul></li><li><p>实验结果：</p><ul><li><p>λ越大、$\epsilon$越小，错误数量越少（<font color="red">总生成图片数量没说？）</font></p><p><img src="/2020/08/20/DeepTest/Fig9.png" alt="Fig9" style="zoom:75%;"></p></li><li><p>对于某些转换，有些模型比其他模型更容易出现错误行为。（$\lambda=5，\epsilon=0.03$）</p><p><img src="/2020/08/20/DeepTest/Fig10.png" alt="Fig10" style="zoom:80%;"></p></li></ul></li></ul></li><li><p>实验4-3：人工检查误报情况</p><ul><li>结果：误报较少</li></ul></li></ul><h3 id="实验5：使用生成图片重新训练DNN能否提高准确率"><a href="#实验5：使用生成图片重新训练DNN能否提高准确率" class="headerlink" title="实验5：使用生成图片重新训练DNN能否提高准确率"></a>实验5：使用生成图片重新训练DNN能否提高准确率</h3><ul><li><p>实验方法：用HMB_3的图片生成雾、雨图片，其中66%和原训练集一起重新训练Epoch模型，剩下34%做测试。<font color="red">（用的转换太少了）</font></p></li><li><p>实验结果：MSE降低。</p></li></ul>]]></content:encoded>
      
      
      <category domain="https://rubychen0611.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</category>
      
      
      <category domain="https://rubychen0611.github.io/tags/DNN%E6%B5%8B%E8%AF%95/">DNN测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95/">模糊测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%B5%8B%E8%AF%95%E8%BE%93%E5%85%A5%E7%94%9F%E6%88%90/">测试输入生成</category>
      
      
      <comments>https://rubychen0611.github.io/2020/08/20/DeepTest/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【论文笔记】TensorFuzz</title>
      <link>https://rubychen0611.github.io/2020/08/20/TensorFuzz/</link>
      <guid>https://rubychen0611.github.io/2020/08/20/TensorFuzz/</guid>
      <pubDate>Thu, 20 Aug 2020 08:56:08 GMT</pubDate>
      
      <description>&lt;p&gt;原文：TensorFuzz: Debugging Neural Networks with Coverage-Guided Fuzzing （ICML’19)&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>原文：TensorFuzz: Debugging Neural Networks with Coverage-Guided Fuzzing （ICML’19) <a id="more"></a></p><p>代码：<a href="https://github.com/brain-research/tensorfuzz">https://github.com/brain-research/tensorfuzz</a></p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="CGF基本流程"><a href="#CGF基本流程" class="headerlink" title="CGF基本流程"></a>CGF基本流程</h3><p><img src="/2020/08/20/TensorFuzz/1.png" alt="1" style="zoom:60%;"></p><h3 id="方法细节"><a href="#方法细节" class="headerlink" title="方法细节"></a>方法细节</h3><ul><li><p>输入选择：选择更新鲜的输入</p></li><li><p>输入变换：①白噪声（参数由用户给出）；②增加$L_{\infty}$约束的白噪声</p></li><li><p>目标函数：用户根据覆盖率和元数据情况自定义</p></li><li><p>覆盖分析器：当我们得到一个新的激活向量时，我们可以查找它的最近邻居，然后检查这个最近的邻居在欧几里得距离中有多远，如果这个距离大于某个量，就向语料中添加输入。</p><ul><li>可只选择部分神经元的值作为激活向量，如只选logits或logits前一层</li></ul></li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="实验1：CGF可以高效地找到已训练神经网络的数值错误（导致NaN的错误）"><a href="#实验1：CGF可以高效地找到已训练神经网络的数值错误（导致NaN的错误）" class="headerlink" title="实验1：CGF可以高效地找到已训练神经网络的数值错误（导致NaN的错误）"></a>实验1：CGF可以高效地找到已训练神经网络的数值错误（导致NaN的错误）</h3><ul><li><p>实验方法：使将检查数值运算添加到元数据并运行模糊测试器（fuzzer）。我们训练了一个完全连接的神经网络来对MNIST数据集里的数字进行分类，故意用了一个很糟糕的交叉熵损失，这样就有可能出现数值误差。模型进行了35000步的训练，mini-batch size为100，验证精度为98%。检查MNIST数据集中不含导致数值误差的样本。</p></li><li><p>实验结果：TensorFuzz 却在10次随机初始化后快速找到了 NaN错误。</p><p><img src="/2020/08/20/TensorFuzz/2.jpg" alt="2" style="zoom:67%;"></p><ul><li>基于梯度的搜索技术可能无助于查找数值误差</li><li>随机搜索对于查找数值误差来说效率极低。</li></ul><h3 id="实验2：CGF-解决模型和量化版本不一致的问题"><a href="#实验2：CGF-解决模型和量化版本不一致的问题" class="headerlink" title="实验2：CGF 解决模型和量化版本不一致的问题"></a>实验2：CGF 解决模型和量化版本不一致的问题</h3><ul><li><p>仅检查已有的数据只能找到很少的错误：作为基线实验，我们训练了一个使用 32 位浮点数的 MNIST 分类器（这一次没有故意引入数值错误）。然后把所有权重和激活值修剪为 16 位。之后，我们对比了 32 位和 16 位模型在 MNIST 测试集上的预测，没有找到任何不一致性。</p></li><li><p>CGF 可以快速在数据周围的小区域中找到很多错误：然后运行 fuzzer，变化限制在种子图像周围的半径为 0.4 的无限范数球中，其中仅使用了 32 位模型作为覆盖的激活值。我们将输入限制在种子图像附近，因为这些输入几乎都有明确的类别语义。模型的两个版本在域外的垃圾数据（没有真实类别）上出现不一致性并没有什么意义。通过这些设置，fuzzer 可以生成 70% 样本的不一致性。因此，CGF 允许我们寻找在测试时出现的真实错误.</p></li></ul><h3 id="实验3：TensorFuzz可以发现流行模型实现中的bug"><a href="#实验3：TensorFuzz可以发现流行模型实现中的bug" class="headerlink" title="实验3：TensorFuzz可以发现流行模型实现中的bug"></a>实验3：TensorFuzz可以发现流行模型实现中的bug</h3><h3 id="实验4：TensorFuzz可以帮助进行保持语义的代码转换"><a href="#实验4：TensorFuzz可以帮助进行保持语义的代码转换" class="headerlink" title="实验4：TensorFuzz可以帮助进行保持语义的代码转换"></a>实验4：TensorFuzz可以帮助进行保持语义的代码转换</h3></li></ul><h2 id="可控制变量及参数总结"><a href="#可控制变量及参数总结" class="headerlink" title="可控制变量及参数总结"></a>可控制变量及参数总结</h2><ul><li><p>输入选择策略</p></li><li><p>变换参数</p></li><li><p>目标函数</p></li><li><p>激活神经元集合</p></li><li><p>距离阈值L</p></li></ul>]]></content:encoded>
      
      
      <category domain="https://rubychen0611.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</category>
      
      
      <category domain="https://rubychen0611.github.io/tags/DNN%E6%B5%8B%E8%AF%95/">DNN测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95/">模糊测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%B5%8B%E8%AF%95%E8%BE%93%E5%85%A5%E7%94%9F%E6%88%90/">测试输入生成</category>
      
      
      <comments>https://rubychen0611.github.io/2020/08/20/TensorFuzz/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【论文笔记】DLFuzz</title>
      <link>https://rubychen0611.github.io/2020/08/20/DLFuzz/</link>
      <guid>https://rubychen0611.github.io/2020/08/20/DLFuzz/</guid>
      <pubDate>Thu, 20 Aug 2020 08:28:39 GMT</pubDate>
      
      <description>&lt;p&gt;原文：DLFuzz: Differential Fuzzing Testing of Deep Learning Systems （ESEC/FSE’18）&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>原文：DLFuzz: Differential Fuzzing Testing of Deep Learning Systems （ESEC/FSE’18）<a id="more"></a></p><p>代码：<a href="https://github.com/turned2670/DLFuzz">https://github.com/turned2670/DLFuzz</a> </p><h2 id="可控制变量及参数总结"><a href="#可控制变量及参数总结" class="headerlink" title="可控制变量及参数总结"></a>可控制变量及参数总结</h2><ul><li>输入集合（未标注）</li><li>待测试DNN</li><li>$k$：除原预测标签外，top-k个其他标签</li><li>$m$：欲覆盖的神经元个数</li><li><p>strategies：神经元选择策略</p><ul><li><p>策略1：选择过去测试中常被覆盖的神经元</p></li><li><p>策略2：选择过去测试中极少被覆盖到的神经元</p></li><li><p>策略3：选择权重高的神经元</p></li><li>策略4：选择激活阈值附近的神经元</li></ul></li><li>$\lambda$：平衡两个目标（预测类别差异和覆盖新的神经元）的参数</li><li>predict_weight：代码里在上公式中$\sum c_i$前的权重，默认为0.5（未在论文里出现的参数）</li><li>iter_times: 每个种子的迭代次数</li><li>threshold: 神经元激活阈值</li><li>learning_step：步长，代码里设为0.02</li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><ul><li><p>梯度约束：<font color="red">论文里说可以加保持符号约束或DeepXplore里的约束，但代码似乎没加任何约束，直接在输入上增加梯度*步长</font></p></li><li><p>生成图像距离约束：满足L2距离（&lt;0.02）（计算方式为L2_norm / orig_L2_norm）</p></li><li><p>约束：一个输入能提升的神经元覆盖率随着时间的增加而下降，对应的保留种子的阈值也随着运行时间的增加而降低<font color="red">（代码里体现为保留种子时最少需要提升的覆盖率随迭代次数增加而降低）</font></p><p><img src="/2020/08/20/DLFuzz/fig1.png" alt="fig1" style="zoom: 80%;"></p></li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集和模型"><a href="#数据集和模型" class="headerlink" title="数据集和模型"></a>数据集和模型</h3><p>MNIST（LeNet-1, LeNet-4, LeNet-5）和ImageNet（VGG-16, VGG-19, ResNet50）</p><font color="red">与DeepXplore相同</font><h3 id="默认参数设置"><a href="#默认参数设置" class="headerlink" title="默认参数设置"></a>默认参数设置</h3><ul><li><p>随机选择20个初始输入<font color="red">（类别是否平衡？20是否过少？）</font></p></li><li><p>$k=4,m=10$，strategy为策略1，iter_times=3 </p></li></ul><h3 id="实验1：DLFuzz与DeepXplore比较"><a href="#实验1：DLFuzz与DeepXplore比较" class="headerlink" title="实验1：DLFuzz与DeepXplore比较"></a>实验1：DLFuzz与DeepXplore比较</h3><ul><li><p>实验方法：对相同的20个初始输入，比较DLFuzz相对DeepXplore神经元覆盖率、l2距离、生成对抗样本的个数、每个对抗样本平均生成时间</p></li><li><p>实验结果：</p><ul><li><p>覆盖率提升<font color="red">（DLFuzz的优化目标选择了10个神经元，DeepXplore只选了一个）</font></p></li><li><p>L2距离很小，生成的扰动更隐秘<font color="red">（DeepXplore未对距离做限制，甚至认为L1距离越大多样性越好）</font></p></li><li><p>生成对抗样本数量更多（DeepXplore对每组DNN每张图片最多只生成一个对抗样本，DLFuzz每个模型每张图片可以生成多个对抗样本）</p></li><li><p>更短的时间消耗（除了ResNet50，因为神经元数量大所以选择神经元的耗时长）</p></li></ul></li></ul><p><img src="/2020/08/20/DLFuzz/fig2.png" alt="fig2" style="zoom:67%;"></p><h3 id="实验2：四种神经元选择策略比较"><a href="#实验2：四种神经元选择策略比较" class="headerlink" title="实验2：四种神经元选择策略比较"></a>实验2：四种神经元选择策略比较</h3><ul><li><p>实验方法：比较四种策略和DeepXplore，随着测试图片生成数量增多，神经元覆盖率的增长趋势</p></li><li><p>实验结果：策略1略好<font color="red">（生成数量是否过少？19张神经元覆盖率就趋于平缓）</font></p><p><img src="/2020/08/20/DLFuzz/fig3.png" alt="fig3" style="zoom:60%;"></p></li></ul><h3 id="实验3：用生成图片重新训练"><a href="#实验3：用生成图片重新训练" class="headerlink" title="实验3：用生成图片重新训练"></a>实验3：用生成图片重新训练</h3><ul><li>实验方法：用生成的114个对抗样本重新训练MNIST的三个DNN模型，平均提升准确率1.8%<font color="red">（太少？）</font></li></ul>]]></content:encoded>
      
      
      <category domain="https://rubychen0611.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</category>
      
      
      <category domain="https://rubychen0611.github.io/tags/DNN%E6%B5%8B%E8%AF%95/">DNN测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%A8%A1%E7%B3%8A%E6%B5%8B%E8%AF%95/">模糊测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%B5%8B%E8%AF%95%E8%BE%93%E5%85%A5%E7%94%9F%E6%88%90/">测试输入生成</category>
      
      
      <comments>https://rubychen0611.github.io/2020/08/20/DLFuzz/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>DNN测试输入生成论文可控制参数及变量总结</title>
      <link>https://rubychen0611.github.io/2020/08/20/Variables-Comparison/</link>
      <guid>https://rubychen0611.github.io/2020/08/20/Variables-Comparison/</guid>
      <pubDate>Thu, 20 Aug 2020 07:39:31 GMT</pubDate>
      
      <description>&lt;h2 id=&quot;共同参数或变量总结&quot;&gt;&lt;a href=&quot;#共同参数或变量总结&quot; class=&quot;headerlink&quot; title=&quot;共同参数或变量总结&quot;&gt;&lt;/a&gt;共同参数或变量总结&lt;/h2&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h2 id="共同参数或变量总结"><a href="#共同参数或变量总结" class="headerlink" title="共同参数或变量总结"></a>共同参数或变量总结<a id="more"></a></h2><ul><li>初始输入种子集合相关变量<ul><li>数量：1个到几千个不等</li><li>采样方式：均为随机<ul><li>DeepXplore还要求了<strong>类别平衡</strong></li></ul></li><li>是否标注<ul><li>若已标注，是否要求<strong>初始预测结果正确</strong>（DeepCT要求了）</li><li>未标注（DeepXplore要求其使用的多个模型预测一致，DLFuzz）</li></ul></li></ul></li><li>测试标准/覆盖率相关变量<ul><li>计算方式<ul><li>DeepTest中修改了卷积层神经元覆盖率的计算方式：输出特征图的平均值与激活阈值做比较</li></ul></li><li>神经元覆盖率采用的激活阈值<ul><li>原算法：将所有输出值缩放到[0,1]，然后设置阈值（<font color="red">离群点等会否导致不同数据集阈值差距很不同</font>）</li><li>DeepXplore中用过多种阈值（0、0.25、0.75等），后人多数用的0，也有0.75等</li></ul></li><li>覆盖神经元集合的选择：<ul><li>多数选择所有层的神经元</li><li>个别选择去掉一些层<ul><li>如DeepXplore测试达到100%覆盖率所用的时间时去掉了全连接层<font color="red">（但覆盖全连接层意义应该更大？）</font></li><li>TensorFuzz要求用户自己选择层</li></ul></li></ul></li></ul></li><li><p>图像上增加的扰动相关变量</p><ul><li>扰动生成方式<ul><li>基于梯度优化</li><li>基于覆盖率引导的模糊测试</li><li>基于约束求解</li><li>基于搜索</li></ul></li><li>扰动种类<ul><li>DeepTest说不同种类变换能激活不同神经元（<font color="red">存疑</font>）</li></ul></li><li>扰动位置：<ul><li>DeepXplore中的单个矩形位置由用户提前设定，多个黑色矩形的位置随机</li></ul></li><li>扰动大小：<ul><li>DeepXplore中的矩形大小由用户提前设定（与数据集图像大小有关）</li></ul></li><li>扰动约束条件：<ul><li>$L_0-norm$<ul><li>如DeepCheck（识别重要像素攻击）</li></ul></li><li>$L_1-norm$<ul><li>DeepXplore未对距离做限制，甚至认为$L_1$距离越<strong>大</strong>多样性越好</li></ul></li><li>$L_2-norm$<ul><li>如DLFuzz：满足L2距离（&lt;0.02）（计算方式为L2_norm / orig_L2_norm）</li></ul></li><li>$L\infty-norm$<ul><li>如TensorFuzz</li></ul></li><li>平衡$L_0$和$L\infty-norm$<ul><li>如DeepHunter采用的</li></ul></li><li>约束MSE（DeepTest)：$|MSE(trans,param)-MSE_{org}|\leq \epsilon$ <font color="red">(用到了oracle)</font></li></ul></li></ul></li><li><p>模糊测试相关变量（DLFuzz、TensorFuzz、DeepHunter、DeepTest）</p><ul><li>判断种子是否应该保留在队列时最少需提升的覆盖率</li><li>每个种子的迭代次数</li><li>从队列中优先挑选哪些种子的策略<ul><li>随机</li><li>选择新鲜的</li><li>平衡新鲜和多样性</li></ul></li></ul></li><li>优化算法相关变量<ul><li>优化目标选择需要新激活的神经元个数？</li></ul></li><li>其他<ul><li>每个种子生成对抗样本的个数<ul><li>有的方法只生成一张，有的多张</li></ul></li><li>蜕变关系<ul><li>图像分类问题：扰动满足约束的情况下，预测类别应该不变</li><li>回归问题：<ul><li>DeepTest：因为只测试了Driving数据集（回归问题），使用MSE判断蜕变关系是否满足$(\theta_i-\theta_{ti}) \leq \lambda MSE_{orig}$</li><li>DeepRoad：没有使用MSE，直接比较输出结果是否小于阈值$\epsilon$</li></ul></li></ul></li></ul></li></ul><h2 id="测试输入生成类论文总结"><a href="#测试输入生成类论文总结" class="headerlink" title="测试输入生成类论文总结"></a>测试输入生成类论文总结</h2><div class="table-container"><table><thead><tr><th style="text-align:center">文章名</th><th>可控制参数/变量总结</th></tr></thead><tbody><tr><td style="text-align:center">DeepXplore<br>(SOSP’17)</td><td><img src="/2020/08/20/Variables-Comparison/DeepXplore.png" alt="DeepXplore"></td></tr><tr><td style="text-align:center">TensorFuzz<br>(ICML’19)</td><td><img src="/2020/08/20/Variables-Comparison/TensorFuzz.png" alt="TensorFuzz" style="zoom:80%;"></td></tr><tr><td style="text-align:center">DeepTest<br>(ICSE’18)</td><td><img src="/2020/08/20/Variables-Comparison/DeepTest.png" alt="DeepTest" style="zoom:80%;"></td></tr><tr><td style="text-align:center">DLFuzz<br>(ESEC/FSE’18)</td><td><img src="/2020/08/20/Variables-Comparison/DLFuzz.png" alt="DLFuzz" style="zoom: 80%;"></td></tr><tr><td style="text-align:center">DeepHunter<br>（ISSTA’19）</td><td><img src="/2020/08/20/Variables-Comparison/DeepHunter.png" alt="DeepHunter" style="zoom:80%;"></td></tr><tr><td style="text-align:center">DeepConcolic<br>（ASE’18）</td><td><img src="/2020/08/20/Variables-Comparison/DeepConcolic.png" alt="DeepConcolic" style="zoom: 80%;"></td></tr><tr><td style="text-align:center">DeepCT<br>(SANER’19)<br><font color="red">(未找到代码)</font></td><td><img src="/2020/08/20/Variables-Comparison/DeepCT.png" alt="DeepCT" style="zoom: 80%;"></td></tr><tr><td style="text-align:center">DeepCheck<br>（ISSRE’18）<br><font color="red">(未找到代码)</font></td><td><img src="/2020/08/20/Variables-Comparison/DeepCheck.png" alt="DeepCheck" style="zoom: 80%;"></td></tr><tr><td style="text-align:center">DeepRoad<br>（ASE’18）<br><font color="red">(未找到代码)</font></td><td><img src="/2020/08/20/Variables-Comparison/DeepRoad.png" alt="DeepRoad" style="zoom:80%;"></td></tr></tbody></table></div>]]></content:encoded>
      
      
      <category domain="https://rubychen0611.github.io/categories/%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0/">科研笔记</category>
      
      
      <category domain="https://rubychen0611.github.io/tags/DNN%E6%B5%8B%E8%AF%95/">DNN测试</category>
      
      
      <comments>https://rubychen0611.github.io/2020/08/20/Variables-Comparison/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【论文笔记】DeepCT</title>
      <link>https://rubychen0611.github.io/2020/08/20/DeepCT/</link>
      <guid>https://rubychen0611.github.io/2020/08/20/DeepCT/</guid>
      <pubDate>Thu, 20 Aug 2020 01:51:42 GMT</pubDate>
      
      <description>&lt;p&gt;原文：DeepCT: Tomographic Combinatorial Testing for Deep Learning Systems （SANER’19 ERA Track Paper)&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>原文：DeepCT: Tomographic Combinatorial Testing for Deep Learning Systems （SANER’19 ERA Track Paper)  <a id="more"></a></p><p>代码：没找到</p><h2 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h2><p>提出了DNN系统的组合测试方法，根据目标要覆盖的神经元激活模式组合，从种子输入开始，通过search-based testing, 或guided random testing, 或symbolic constraint solving based testing方法生成满足条件的输入，同时最小化L∞距离。以生成覆盖更多的神经元激活模式组合的输入。</p><h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><ul><li>为什么层析（tomographic）？<ul><li>DNN学习到的特征随着层数增加越来越复杂、抽象</li></ul></li><li>为什么组合（combinatorial）？<ul><li>每层神经元只与前后两层发生交互。逻辑单元之间可能存在逻辑(无形)的相互作用，其中当前层的神经元共同决定其下一层神经元的逻辑。我们想用CT捕捉和检查每一层神经元之间的这些无形的相互作用。</li></ul></li></ul><h2 id="组合测试标准"><a href="#组合测试标准" class="headerlink" title="组合测试标准"></a>组合测试标准</h2><h3 id="神经元激活配置（Neuron-activation-configuration"><a href="#神经元激活配置（Neuron-activation-configuration" class="headerlink" title="神经元激活配置（Neuron-activation configuration)"></a>神经元激活配置（Neuron-activation configuration)</h3><p>对第$i$层的一组神经元$M=\{n_1,n_2,…,n_k\}$，激活配置为一个元组$c=(b_1,b_2,…,b_k)$，其中$b_i \in \{0,1\}$。若测试集$T$中存在样本$t$能使得激活模式等于$c$，则称$T$可以覆盖$c$。</p><p>$\Theta(t,L_i)$: 第$i$层神经元所有$t$-路覆盖组合</p><p>$\theta \in \Theta(t,L_i)$：是$t$个神经元的集合，拥有$2^t$种激活配置</p><p>$\Theta_{Full}(t,L_i,T) \subseteq \Theta(t,L_i)$：能被$T$完全覆盖的$t$-路覆盖组合</p><h3 id="t-路组合稀疏覆盖"><a href="#t-路组合稀疏覆盖" class="headerlink" title="$t$-路组合稀疏覆盖"></a>$t$-路组合稀疏覆盖</h3><p>$T$的组合稀疏覆盖=覆盖了所有神经元配置的组合数 / 所有组合数</p><p>例子：</p><p><img src="/2020/08/20/DeepCT/fig1.png" alt="fig1" style="zoom:60%;"></p><p>$L_i$层中共有4个神经元${n1,n2,n3,n4}$，<br>2-路组合共有六种：$\{n1,n2\}，\{n1,n3\}，\{n1,n4\}，\{n2,n3\}，\{n2,n4\}，\{n3,n4\}$<br>每个2-路组合有四种神经元激活配置$(0，0)、(0，1)、(1，0)$和$(1，1)$<br>在6个双向组合中，T只覆盖了$\{n1，n2\}，\{n1，n4\}，\{n2，n3\}$和$\{n3，n4\}$的四种神经元激活配置(只有这四个组合出现了四种神经元激活配置)<br>则Li层的2-路组合稀疏覆盖率$= 4 / 6= 66.6\%$</p><p>由于$t$-路组合稀疏覆盖不能考虑每个神经元组合内的覆盖，接下来我们引入t-way组合稠密覆盖。</p><h3 id="t-路组合稠密覆盖"><a href="#t-路组合稠密覆盖" class="headerlink" title="$t$-路组合稠密覆盖"></a>$t$-路组合稠密覆盖</h3><p>$T$的组合稀疏覆盖= 被覆盖了的激活配置数 / 所有组合的所有激活配置数目</p><p>例子：同上图</p><p>由于$L_i$中有六个神经元的双向组合，并且每个组合有四个神经元激活配置,总共有24种激活配置</p><p>测试集T可以覆盖20种配置，未覆盖的神经元激活配置为$\{n1，n3\}=(0，1)，\{n1，n3\}=(1，0)，\{n2，n4\}=(0，1)，\{n2，n4\}=(1，0)$,因此，T的双向组合密集覆盖率为83.3%。</p><h3 id="p-t-完备性"><a href="#p-t-完备性" class="headerlink" title="$(p,t)$完备性"></a>$(p,t)$完备性</h3><p>达到$p$(百分比)覆盖的组合比例</p><p>例子：同上图</p><p>在神经元的双向组合中，$\{n1，n2\}，\{n1，n4\}，\{n2，n3\}，\{n3，n4\}$的覆盖双向构型比为100%，$\{n1，n3\}$和$\{n2，n4\}$的覆盖双向构型比为50%。则$L_i$的(0.5，2)-完备性为100%，$L_i$的(1，2)-完备性为66.6%。即达到100%覆盖的有4个,达到50%以上覆盖的有6个。</p><h2 id="DNN的鲁棒性测试"><a href="#DNN的鲁棒性测试" class="headerlink" title="DNN的鲁棒性测试"></a>DNN的鲁棒性测试</h2><h3 id="d-局部鲁棒性"><a href="#d-局部鲁棒性" class="headerlink" title="$d$-局部鲁棒性"></a>$d$-局部鲁棒性</h3><script type="math/tex; mode=display">\forall x':\parallel x'-x \parallel \leq d \Rightarrow C(x) = C(x')</script><p>约束：$L_{\infty}-norm$</p><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p><img src="/2020/08/20/DeepCT/al.png" alt="al" style="zoom:67%;"></p><ul><li>输入<ul><li>DNN</li><li>$t$:测试粒度，每个组合内神经元个数</li><li>组合测试标准</li><li>初始种子集合</li></ul></li><li>输出<ul><li>正确样本集合</li><li>对抗样本集合</li></ul></li><li>测试用例生成方法<ul><li>没有特殊规定，<font color="red">基于搜索、覆盖率引导的随机测试、符号分析/约束求解都可以</font></li><li>本文实验：DNN使用ReLU激活函数，约束求解方法（Cplex solver）生成测试用例<ul><li><font color="red">即将CT覆盖目标编码为目标的线性约束，使种子输入的$L_{\infty}$-范数扰动距离最小。</font></li></ul></li></ul></li></ul><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul><li>数据集和模型<ul><li>MNIST和两个预训练好的DNN模型DNN1和DNN2（结构和精度略）</li></ul></li><li>从原测试集随机选择1000个样本作为初始种子，<font color="red">且这1000个都能被原DNN正确分类</font></li><li>随机测试（Random Testing)<ul><li><font color="red">随机生成10000个测试用例（如何随机生成的？）</font>，然后检测健壮性问题</li><li>实验结果：RT已经能够检测到DNN1上的194个样本和DNN2上的178个样本的健壮性问题，总共266个独特的问题，其中106个是DNN1和DNN2上共同的问题。</li></ul></li><li>DeepCT测试<ul><li>1000个样本中去掉266个随机测试已经发现问题的样本，剩余的734个样本中随机采样50个进一步分析$d$-局部鲁棒性（$d$设为0.15，使用2-路CT标准）</li><li>实验结果：<ul><li>生成图片数量相当的情况下，DeepCT达到的覆盖率远超随机测试</li><li>随着测试层数和生成的测试用例增加，覆盖率也逐渐增加</li></ul></li></ul></li></ul><p><img src="/2020/08/20/DeepCT/fig2.png" alt="fig2" style="zoom:60%;"></p><h2 id="可控制参数-变量总结"><a href="#可控制参数-变量总结" class="headerlink" title="可控制参数/变量总结"></a>可控制参数/变量总结</h2><ul><li>$t$：覆盖粒度</li><li>$d$：鲁棒性约束</li><li>$L_{\infty}$约束的参数</li><li>初始种子集合</li><li>$p$：完备性指标</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="https://blog.csdn.net/qq_33935895/article/details/105454414">https://blog.csdn.net/qq_33935895/article/details/105454414</a></p>]]></content:encoded>
      
      
      <category domain="https://rubychen0611.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</category>
      
      
      <category domain="https://rubychen0611.github.io/tags/DNN%E6%B5%8B%E8%AF%95/">DNN测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%B5%8B%E8%AF%95%E8%BE%93%E5%85%A5%E7%94%9F%E6%88%90/">测试输入生成</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%B5%8B%E8%AF%95%E6%A0%87%E5%87%86/">测试标准</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E7%BB%84%E5%90%88%E6%B5%8B%E8%AF%95/">组合测试</category>
      
      
      <comments>https://rubychen0611.github.io/2020/08/20/DeepCT/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【论文笔记】DeepXplore</title>
      <link>https://rubychen0611.github.io/2020/08/19/DeepXplore/</link>
      <guid>https://rubychen0611.github.io/2020/08/19/DeepXplore/</guid>
      <pubDate>Wed, 19 Aug 2020 13:59:46 GMT</pubDate>
      
      <description>&lt;p&gt;原文：DeepXplore: Automated Whitebox Testing of Deep Learning Systems（SOSP’17）&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>原文：DeepXplore: Automated Whitebox Testing of Deep Learning Systems（SOSP’17）<a id="more"></a></p><p>代码地址：<a href="https://github.com/peikexin9/deepxplore">https://github.com/peikexin9/deepxplore</a></p><h2 id="可控制参数或变量"><a href="#可控制参数或变量" class="headerlink" title="可控制参数或变量"></a>可控制参数或变量</h2><ul><li><p>种子输入集合数量 (类别均衡，随机选择，<u>约束：所有DNN模型必须对每个种子的初始预测结果相同</u>)</p></li><li><p>多个DNN</p></li><li><p>$\lambda_1$：平衡其他DNN和被选中DNN预测的差别（$\lambda_1$越大，选中DNN预测为原类别c的概率越低，$\lambda_1$越小，越能维持其他DNN的预测结果）</p><p><img src="/2020/08/19/DeepXplore/1.png" alt="公式1"></p></li><li><p>$\lambda_2$：平衡两个优化目标大小（即预测差异和神经元覆盖率，$\lambda_2$越大，越关注覆盖更多神经元，否则更关注生成预测差异图片）</p></li></ul><p><img src="/2020/08/19/DeepXplore/2.png" alt="公式2"></p><ul><li>$s$: 梯度下降步长（$s$过大可能会导致极小值附近震荡，$s$过小导致迭代次数多）</li><li>$t$: 神经元覆盖率阈值（$t$越大，达到覆盖率目标越难）</li><li>$p$: 覆盖率目标</li><li>梯度下降迭代最大次数（代码里）</li><li><font color="red">在每次迭代的梯度$G$上施加的真实领域约束:</font><ul><li>（1）不同亮度模拟光照：$G$被$mean(G)$ 取代</li><li>（2）单个矩形($m*n$大小)模拟意外或故意遮挡：<ul><li>选择矩形左上顶点所在的位置$(i,j)$，将$G_{i:i+m,j:j+n}$施加于原图相应位置。</li><li><font color="red">$m$、$n$的大小和$(i,j)$为自定义的参数，迭代多次都在相同位置</font></li></ul></li><li>（3） 多个随机黑色小矩形模拟镜头污垢<ul><li>位置随机的若干个$m*m$大小的黑色矩形<font color="red">（每次迭代位置不同，$m$值自定义，与数据集图片大小有关）</font></li><li>如果$mean(G_{i:i+m,j:j+m})$，则图片不动，否则变黑（即只允许降低像素值）</li></ul></li></ul></li></ul><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p><img src="/2020/08/19/DeepXplore/算法.png" alt="算法" style="zoom:80%;"></p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集和模型"><a href="#数据集和模型" class="headerlink" title="数据集和模型"></a>数据集和模型</h3><p><img src="/2020/08/19/DeepXplore/dataset.png" alt="dataset"></p><h3 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h3><ul><li>种子输入集合：随机从测试集选择2000个输入（保持<font color="red">类别平衡</font>，满足所有DNN预测结果相同的约束）</li><li>参数$\lambda_1,\lambda_2,s,t$</li></ul><p><img src="/2020/08/19/DeepXplore/para.png" alt="para" style="zoom:67%;"></p><h3 id="实验1：神经元覆盖率的优势"><a href="#实验1：神经元覆盖率的优势" class="headerlink" title="实验1：神经元覆盖率的优势"></a>实验1：神经元覆盖率的优势</h3><h4 id="实验1-1：神经元覆盖率与代码覆盖率比较"><a href="#实验1-1：神经元覆盖率与代码覆盖率比较" class="headerlink" title="实验1-1：神经元覆盖率与代码覆盖率比较"></a>实验1-1：神经元覆盖率与代码覆盖率比较</h4><ul><li><p>实验方法：随机选择10个测试输入，测量代码覆盖率和神经元覆盖率大小</p></li><li><p>参数设置：设置$t=0.75$（神经元激活阈值，<font color="red">按比例缩放至[0,1]区间，不同DNN阈值区别很大？）前面都设的0，故意设大t凸显结果差异）</font></p></li><li><p>实验结果：少量测试输入即可达到100%代码覆盖率，但神经元覆盖率最多只有34%：</p><p><img src="/2020/08/19/DeepXplore/ex1-1.png" alt="ex1-1" style="zoom:80%;"></p></li></ul><h4 id="实验1-2：神经元覆盖率对DeepXplore生成能导致预测差异样本的作用"><a href="#实验1-2：神经元覆盖率对DeepXplore生成能导致预测差异样本的作用" class="headerlink" title="实验1-2：神经元覆盖率对DeepXplore生成能导致预测差异样本的作用"></a>实验1-2：神经元覆盖率对DeepXplore生成能导致预测差异样本的作用</h4><ul><li>实验方法：从MNIST测试集随机选择2000种子输入，分别设置$\lambda_2$为1和0（$\lambda_2=0$时优化目标里不考虑覆盖新的神经元）。测量生成预测差异样本（difference-inducing inputs）的多样性<strong>（平均$L_1$距离：改变前后像素值之差的和，<font color="red">是否适合作为衡量多样性的指标？</font>）</strong></li><li>参数设置：$t=0.25$</li><li>实验结果：神经元覆盖率帮助提升了生成样本的多样性<font color="red">（①神经元覆盖率NC提升并不明显？作者的解释是NC很高的情况下，NC的一点点提升就能带来多样性的大幅提升。②生成数量#Diffs减少了：作者的解释是设置$\lambda_2=1$后更倾向于生成不同输入而不是提高输入数量，作者认为生成数量并不是一个好的衡量生成样本的方式）</font></li></ul><p><img src="/2020/08/19/DeepXplore/ex1-2.png" alt="ex1-2" style="zoom:75%;"></p><h4 id="实验1-3：不同类别输入对激活神经元的影响"><a href="#实验1-3：不同类别输入对激活神经元的影响" class="headerlink" title="实验1-3：不同类别输入对激活神经元的影响"></a>实验1-3：不同<strong><em>类别</em></strong>输入对激活神经元的影响</h4><ul><li>实验方法：MNIST数据集的LeNet-5模型，运行100对相同类别（如类别8）图片，和100对不同类别（如类别8和类别4）图片，测量平均激活神经元个数和共同激活神经元的个数（overlap）。</li><li>实验结果：相同类别共同激活的平均神经元个数$&gt;$不同类别。神经元覆盖率可以有效地估计DNN测试中激活的不同规则的数量。</li></ul><p><img src="/2020/08/19/DeepXplore/ex1-3.png" alt="ex1-3" style="zoom:80%;"></p><h3 id="实验2：DeepXplore的效果"><a href="#实验2：DeepXplore的效果" class="headerlink" title="实验2：DeepXplore的效果"></a>实验2：DeepXplore的效果</h3><h4 id="实验2-1：DeepXplore在神经元覆盖率上的表现"><a href="#实验2-1：DeepXplore在神经元覆盖率上的表现" class="headerlink" title="实验2-1：DeepXplore在神经元覆盖率上的表现"></a>实验2-1：DeepXplore在神经元覆盖率上的表现</h4><ul><li><p>实验方法：使用三种方法（DeepXplore、对抗样本FGSM、原测试集随机选择）生成相同数量（测试集的1%）的输入，比较神经元覆盖率</p></li><li><p>实验结果：DeepXplore能达到更高的覆盖率，且随着$t$的提升，覆盖率逐渐降低。</p></li></ul><p><img src="/2020/08/19/DeepXplore/ex2-1.png" alt="ex2-1"></p><h4 id="实验2-2：运行时间"><a href="#实验2-2：运行时间" class="headerlink" title="实验2-2：运行时间"></a>实验2-2：运行时间</h4><ul><li><p>实验方法：不同数据集和模型生成100%覆盖率输入所需时间及相应的生成数量。<font color="red">所有图像分类模型不考虑全连接层的覆盖（作者解释因为全连接层有的神经元非常难覆盖到，但全连接层的覆盖情况应该意义更大？）</font></p></li><li><p>实验结果：DeepXplore生成高覆盖率的输入效率非常高。</p></li></ul><p><img src="/2020/08/19/DeepXplore/ex2-2.png" alt="ex2-2" style="zoom: 67%;"></p><h4 id="实验2-3：不同参数设置的影响"><a href="#实验2-3：不同参数设置的影响" class="headerlink" title="实验2-3：不同参数设置的影响"></a>实验2-3：不同参数设置的影响</h4><ul><li>实验方法：改变参数$s$、$\lambda_1$、$\lambda_2$，比较<font color="red">找到第一个导致预测差异的输入平均运行时间（这个指标是否足够适合评价参数？）</font></li><li>实验结果</li></ul><p><img src="/2020/08/19/DeepXplore/ex2-3.png" alt="ex2-3" style="zoom:67%;"></p><p><img src="/2020/08/19/DeepXplore/ex2-4.png" alt="ex2-4" style="zoom:60%;"></p><h4 id="实验2-4：当多个DNN决策边界相似时DeepXplore的效果"><a href="#实验2-4：当多个DNN决策边界相似时DeepXplore的效果" class="headerlink" title="实验2-4：当多个DNN决策边界相似时DeepXplore的效果"></a>实验2-4：当多个DNN决策边界相似时DeepXplore的效果</h4><ul><li>实验方法：<ul><li>对照组：MNIST训练集（60000个样本）和LeNet-1模型，10个epoch</li><li>实验组：改变①训练集样本个数，②DNN卷积层模型filter个数，③训练epoch数</li><li>设置初始种子数为100，对比发现生成第一个使得实验组DNN和对照组DNN预测差异样本的平均迭代次数</li></ul></li><li>实验结果：DeepXplore从非常相似的DNN中也能发现错误样本（除了第一行diff为1时），越相似，迭代轮数越多。</li></ul><p><img src="/2020/08/19/DeepXplore/ex2-5.png" alt="ex2-5" style="zoom:67%;"></p><h3 id="实验3：使用DeepXplore提升DNN"><a href="#实验3：使用DeepXplore提升DNN" class="headerlink" title="实验3：使用DeepXplore提升DNN"></a>实验3：使用DeepXplore提升DNN</h3><h4 id="实验3-1：使用生成样本扩大训练集，重新训练DNN"><a href="#实验3-1：使用生成样本扩大训练集，重新训练DNN" class="headerlink" title="实验3-1：使用生成样本扩大训练集，重新训练DNN"></a>实验3-1：使用生成样本扩大训练集，重新训练DNN</h4><ul><li>与对抗样本训练不同的是：不需标注（采取投票形式）</li><li>实验方法：重新训练MNIST数据集的三个模型5个epoch，增加100张DeepXplore生成的错误图片，与对抗样本和随机从测试集选择样本比较准确率。<font color="red">（测试样本是什么？多个DNN从何而来？）</font></li><li>实验结果：DeepXplore平均提升准确率1%-3%</li></ul><p><img src="/2020/08/19/DeepXplore/ex3-1.png" alt="ex3-1" style="zoom:85%;"></p><h4 id="实验3-2：检测被污染的训练样本"><a href="#实验3-2：检测被污染的训练样本" class="headerlink" title="实验3-2：检测被污染的训练样本"></a>实验3-2：检测被污染的训练样本</h4><ul><li>实验过程：用两个MNIST LeNet-5模型，一个正常训练，另一个类别9的样本中30%被故意标记成了类别1。使用DeepXplore生成被错误预测成9或1的样本，在训练集中找和错误样本结构相似的样本。能识别出95.6%的污染样本。<font color="red">（写得很简略）</font></li></ul>]]></content:encoded>
      
      
      <category domain="https://rubychen0611.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</category>
      
      
      <category domain="https://rubychen0611.github.io/tags/DNN%E6%B5%8B%E8%AF%95/">DNN测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%B5%8B%E8%AF%95%E8%BE%93%E5%85%A5%E7%94%9F%E6%88%90/">测试输入生成</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%B5%8B%E8%AF%95%E6%A0%87%E5%87%86/">测试标准</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E5%B7%AE%E5%88%86%E6%B5%8B%E8%AF%95/">差分测试</category>
      
      
      <comments>https://rubychen0611.github.io/2020/08/19/DeepXplore/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>【论文笔记】DeepConcolic</title>
      <link>https://rubychen0611.github.io/2020/08/19/DeepConcolic/</link>
      <guid>https://rubychen0611.github.io/2020/08/19/DeepConcolic/</guid>
      <pubDate>Wed, 19 Aug 2020 06:41:03 GMT</pubDate>
      
      <description>&lt;p&gt;原文：Concolic Testing for Deep Neural Networks （ASE’18)&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>原文：Concolic Testing for Deep Neural Networks （ASE’18) <a id="more"></a></p><p>代码地址：<a href="https://github.com/TrustAI/DeepConcolic">https://github.com/TrustAI/DeepConcolic</a> （利普希茨覆盖测试部分用MATLAB写的）</p><h2 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h2><ul><li>提出了第一种DNN的Concolic测试方法。通过具体执行获得激活模式，通过反转神经元的值，优化得到变换后的输入（类似约束求解器）。使测试集达到高覆盖率。</li><li><p>提出利普希茨常数覆盖标准。</p></li><li><p>与其他方法比较：</p></li></ul><p><img src="/2020/08/19/DeepConcolic/compare.png" alt="compare"></p><font color="red">（DeepTest中的Jaccard距离并不是用来约束图片距离的，只是比较激活神经元的差异）</font><h2 id="形式化定义"><a href="#形式化定义" class="headerlink" title="形式化定义"></a>形式化定义</h2><h3 id="激活模式"><a href="#激活模式" class="headerlink" title="激活模式"></a>激活模式</h3><p>$ap[t]_{k,l} \in \{true,false\}$ 表示输入$t$的第$k$层第$l$个神经元是否被$ReLU$函数激活。</p><h3 id="覆盖要求"><a href="#覆盖要求" class="headerlink" title="覆盖要求"></a>覆盖要求</h3><p>略，公式较多但比较好理解，逻辑形式表达覆盖标准。</p><h3 id="覆盖要求的可满足性"><a href="#覆盖要求的可满足性" class="headerlink" title="覆盖要求的可满足性"></a>覆盖要求的可满足性</h3><p>给定一组测试用例$T$和覆盖要求$r$  ，$T \vDash r$表示测试用例满足了覆盖要求。</p><h3 id="覆盖要求的复杂度"><a href="#覆盖要求的复杂度" class="headerlink" title="覆盖要求的复杂度"></a>覆盖要求的复杂度</h3><p>检查$T \vDash r$需要能在多项式时间内完成。</p><h3 id="覆盖率"><a href="#覆盖率" class="headerlink" title="覆盖率"></a>覆盖率</h3><p>给定一个覆盖要求的集合$R$,测试用例集$T$可满足要求的数量所占比例即覆盖率。</p><h2 id="特定覆盖要求介绍"><a href="#特定覆盖要求介绍" class="headerlink" title="特定覆盖要求介绍"></a>特定覆盖要求介绍</h2><p>本节用上面的方法形式化定义了目前学术界已有的一些覆盖标准。</p><h3 id="利普希茨连续条件（Lipschitz-Continuity）"><a href="#利普希茨连续条件（Lipschitz-Continuity）" class="headerlink" title="利普希茨连续条件（Lipschitz Continuity）"></a>利普希茨连续条件（Lipschitz Continuity）</h3><p>对一个神经网络$N$，若存在$c\geq0$，使得对输入样本集合$D_{L1}$中的任意两个样本$x_1$、$x_2$，满足：</p><script type="math/tex; mode=display">\parallel v[x_1]_1-v[x_2]_1 \parallel \leq c \cdot \parallel x_1-x_2 \parallel</script><p>其中$v[x]_1$表示<font color="red">输入层</font>神经元的激活向量（？），$c$为利普希茨常数。满足条件的最小的$c$称为最佳利普希茨常数$c_{best}$。</p><p>利普希茨覆盖：是一组覆盖要求的集合，要求体现了给定输入子空间中的任意两个输入$x_1$、$x_2$满足上述利普希茨连续条件的情况</p><h3 id="神经元覆盖率（NC）"><a href="#神经元覆盖率（NC）" class="headerlink" title="神经元覆盖率（NC）"></a>神经元覆盖率（NC）</h3><p>DeepXplore中定义的神经元覆盖率，形式化表示为一组覆盖标准：</p><p>$\{\exists x.ap[x]_{k,i}=true|2\leq k \leq K-1,1 \leq i \leq s_k\}$</p><p>即对每个神经元提出一个覆盖要求——存在输入x能将其激活。</p><h3 id="MC-DC覆盖率（SS-coverage）"><a href="#MC-DC覆盖率（SS-coverage）" class="headerlink" title="MC/DC覆盖率（SS coverage）"></a>MC/DC覆盖率（SS coverage）</h3><p>DeepCover提出，</p><h3 id="神经元边缘覆盖率（NBC）"><a href="#神经元边缘覆盖率（NBC）" class="headerlink" title="神经元边缘覆盖率（NBC）"></a>神经元边缘覆盖率（NBC）</h3><p>DeepGauge中提出，</p><h2 id="本文方法"><a href="#本文方法" class="headerlink" title="本文方法"></a>本文方法</h2><h3 id="算法概览"><a href="#算法概览" class="headerlink" title="算法概览"></a>算法概览</h3><p><img src="/2020/08/19/DeepConcolic/overview.png" alt="overview" style="zoom:80%;"></p><p><img src="/2020/08/19/DeepConcolic/算法.png" alt="算法" style="zoom:60%;"></p><ul><li>输入<ul><li>一个DNN $N$</li><li>一个输入样本$t_0$</li><li>一组覆盖要求$R$</li><li>启发式$\delta$：<font color="red">与选择的覆盖要求有关，使得第7行能尽可能找到一组容易满足的要求</font></li></ul></li><li>输出：<ul><li>一组测试样本$T$，最初只包含$t_0$</li></ul></li><li><p>validity_check函数：检查$t’$是否有效</p></li><li><p>当$R$中所有要求被满足或不能满足$R$中的其他要求时算法停止</p></li></ul><h3 id="要求评估（requirement-evaluation函数，具体执行部分"><a href="#要求评估（requirement-evaluation函数，具体执行部分" class="headerlink" title="要求评估（requirement_evaluation函数，具体执行部分)"></a>要求评估（requirement_evaluation函数，具体执行部分)</h3><ul><li><p>寻找一组$(t,r)$，使得$t$变换成$t’$后最有可能满足要求$r$。</p></li><li><p>定义$arg max_x a:e$ ：满足布尔表达式$e$的所有样本里，使得算数表达式$a$最大的$x$</p></li><li><p>启发式：略，得到使得覆盖要求表达式（即前面的四种覆盖率）值取到最大的样本</p><ul><li>利普希茨连续</li><li>NC</li><li>SSC</li><li>NBC</li></ul></li></ul><h3 id="符号分析（symbolic-analysis函数）"><a href="#符号分析（symbolic-analysis函数）" class="headerlink" title="符号分析（symbolic_analysis函数）"></a>符号分析（symbolic_analysis函数）</h3><p>根据$(t,r)$变换$t$生成$t’$，有三种方法：</p><h4 id="1、利用线性编程进行符号分析"><a href="#1、利用线性编程进行符号分析" class="headerlink" title="1、利用线性编程进行符号分析"></a>1、利用线性编程进行符号分析</h4><p>将DNN实例$N(x)$映射到可以使用线性编程(LP)建模的激活模式$ap[x]$，并根据不同覆盖准则定义新的激活模式$ap’[x]$:</p><ul><li>NC：反转某神经元$n_{k,i}$的值，保持第$k$层之前的层的输出不变，因为该神经元只受之前层的影响。之后层的输出不用管。</li><li>SSC：反转$n_{k+1,j}$和$n_{k,i}$</li><li>NBC：目标使得神经元$n_{k,i}$的激活值超过其上界或低于其下界</li></ul><p>LP模型将对$ap’[x]$进行编码并求解满足要求$r$的输入$t’$</p><h4 id="2、基于全局优化的符号分析"><a href="#2、基于全局优化的符号分析" class="headerlink" title="2、基于全局优化的符号分析"></a>2、基于全局优化的符号分析</h4><p>基于全局优化算法达到上述目标生成$t’$</p><h4 id="3、Lipschitz测试用例生成"><a href="#3、Lipschitz测试用例生成" class="headerlink" title="3、Lipschitz测试用例生成"></a>3、Lipschitz测试用例生成</h4><p>本文提出了一种新颖的交替式罗盘搜索方案（略）</p><h3 id="测试预言（约束）"><a href="#测试预言（约束）" class="headerlink" title="测试预言（约束）"></a>测试预言（约束）</h3><p>给定实数$b$，如果测试用例$t’ \in T$满足：</p><script type="math/tex; mode=display">\parallel t-t' \parallel \leq b</script><p>则称$t’$为有效的。若$t$与$t’$的预测结果一致，则称DNN通过了测试预言。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul><li>时间限制：12h</li><li>所有覆盖结果均运行10次以上取平均</li></ul><h3 id="实验1：与DeepXplore对比"><a href="#实验1：与DeepXplore对比" class="headerlink" title="实验1：与DeepXplore对比"></a>实验1：与DeepXplore对比</h3><ul><li><p>数据集：MNIST、CIFAR-10</p></li><li><p>实验方法</p><ul><li>从随机采样的初始种子集合开始</li><li>DeepXplore要求多个模型差分测试：采用目标测试的DNN模型+DeepXplore论文里的2个模型</li><li>比较二者达到的覆盖率</li></ul></li><li><p>实验结果</p><p><img src="/2020/08/19/DeepConcolic/ex1.png" alt="ex1" style="zoom:70%;"></p><ul><li>DeepConcolic能达到比DeepXplore更高的覆盖率</li><li>但DeepXplore更快，几秒内运行结束<font color="red">（没有说DeepConcolic的运行时间）</font></li><li>生成的图像：<font color="red">(几乎完全反相也符合约束？)</font></li></ul><p><img src="/2020/08/19/DeepConcolic/ex1-2.png" alt="ex1-2" style="zoom:67%;"></p></li></ul><h3 id="实验2：比较NC-SCC和NBC"><a href="#实验2：比较NC-SCC和NBC" class="headerlink" title="实验2：比较NC, SCC和NBC"></a>实验2：比较NC, SCC和NBC</h3><ul><li><p>实验方法</p><ul><li>NC：从一张初始种子开始</li><li>SCC和NBC：初始集合包含1000张图片，且仅测试一部分神经元<font color="red">（和NC差别很大）</font></li><li>设置$L _\infty$的距离上界为0.3，$L_0$的距离上界为100个像素</li></ul></li><li><p>实验结果</p><p><img src="/2020/08/19/DeepConcolic/MyBlog\source\_posts\DeepConcolic\ex2-1.png" alt="ex2-1" style="zoom:70%;"></p><p><img src="/2020/08/19/DeepConcolic/ex2-3.png" alt="ex2-3"></p><ul><li><p>使用全局优化进行符号分析的开销太高。因此，具有$L_0$范数的SSC结果被排除在外。<font color="red">(?右图没有蓝色条形)</font></p></li><li><p>总体而言，DeepConcolic实现了高覆盖率，并使用健壮性检查检测到大量的对抗性示例。然而，NBC的覆盖范围是有限的</p></li><li><p>concolic测试可以发现距离极小的对抗样本：如1255≈0.0039（$L_{\infty}$范数），1像素（$L_0$范数）</p></li><li><p>对抗样本的平均距离：(对于同一网络，当距离度量改变时，使用NC发现的对抗性示例的数量可能会有很大变化。在设计DNN的覆盖标准时，需要使用各种距离度量来检查它们。)</p><p><img src="/2020/08/19/DeepConcolic/ex2-2.png" alt="ex2-2" style="zoom:67%;"></p></li></ul></li></ul><h3 id="实验3：利普希茨常数检验结果"><a href="#实验3：利普希茨常数检验结果" class="headerlink" title="实验3：利普希茨常数检验结果"></a>实验3：利普希茨常数检验结果</h3><p><img src="/2020/08/19/DeepConcolic/ex3-1.png" alt="ex3-1" style="zoom:80%;"></p><ul><li>我们通过随机测试生成的方式产生了100万个测试对，但最大Lipschitz转换率只达到了3.23，并且大多数测试对都在[0.01，2]的范围内。另一方面，我们的Concolic方法可以覆盖[0.01，10.38]的Lipschitz范围，其中大多数情况位于[3.5，10]，而随机测试生成很难覆盖这一范围。</li><li>目标：覆盖较大Lipschitz常数范围。如对于自动驾驶汽车等安全关键应用，Lipschitz常数较大的DNN本质上表明它更容易受到对手的扰动。因此，可以覆盖较大Lipschitz常数的测试方法为训练的DNN提供了有用的鲁棒性指标。我们认为，对于DNNs的安全测试，Lipschitz常数覆盖的Concolic测试方法可以补充现有的方法来实现更好的覆盖。</li></ul><h2 id="可控制参数和变量总结"><a href="#可控制参数和变量总结" class="headerlink" title="可控制参数和变量总结"></a>可控制参数和变量总结</h2><ul><li>初始样本集合</li><li>覆盖标准：利普希茨常数覆盖、NC、NBC、SSC</li><li>变换约束条件（$L_\infty$、$L_0$及其参数）</li><li>测试的神经元（全部还是部分）</li></ul>]]></content:encoded>
      
      
      <category domain="https://rubychen0611.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</category>
      
      
      <category domain="https://rubychen0611.github.io/tags/DNN%E6%B5%8B%E8%AF%95/">DNN测试</category>
      
      <category domain="https://rubychen0611.github.io/tags/%E6%B5%8B%E8%AF%95%E8%BE%93%E5%85%A5%E7%94%9F%E6%88%90/">测试输入生成</category>
      
      <category domain="https://rubychen0611.github.io/tags/Concolic%E6%B5%8B%E8%AF%95/">Concolic测试</category>
      
      
      <comments>https://rubychen0611.github.io/2020/08/19/DeepConcolic/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
