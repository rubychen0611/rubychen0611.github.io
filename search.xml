<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>【论文笔记】DeepCT</title>
    <url>/2020/08/20/DeepCT/</url>
    <content><![CDATA[<p>原文：DeepCT: Tomographic Combinatorial Testing for Deep Learning Systems （SANER’19 ERA Track Paper)  <a id="more"></a></p>
<p>代码：没找到</p>
<h2 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h2><p>提出了DNN系统的组合测试方法，根据目标要覆盖的神经元激活模式组合，从种子输入开始，通过search-based testing, 或guided random testing, 或symbolic constraint solving based testing方法生成满足条件的输入，同时最小化L∞距离。以生成覆盖更多的神经元激活模式组合的输入。</p>
<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><ul>
<li>为什么层析（tomographic）？<ul>
<li>DNN学习到的特征随着层数增加越来越复杂、抽象</li>
</ul>
</li>
<li>为什么组合（combinatorial）？<ul>
<li>每层神经元只与前后两层发生交互。逻辑单元之间可能存在逻辑(无形)的相互作用，其中当前层的神经元共同决定其下一层神经元的逻辑。我们想用CT捕捉和检查每一层神经元之间的这些无形的相互作用。</li>
</ul>
</li>
</ul>
<h2 id="组合测试标准"><a href="#组合测试标准" class="headerlink" title="组合测试标准"></a>组合测试标准</h2><h3 id="神经元激活配置（Neuron-activation-configuration"><a href="#神经元激活配置（Neuron-activation-configuration" class="headerlink" title="神经元激活配置（Neuron-activation configuration)"></a>神经元激活配置（Neuron-activation configuration)</h3><p>对第$i$层的一组神经元$M=\{n_1,n_2,…,n_k\}$，激活配置为一个元组$c=(b_1,b_2,…,b_k)$，其中$b_i \in \{0,1\}$。若测试集$T$中存在样本$t$能使得激活模式等于$c$，则称$T$可以覆盖$c$。</p>
<p>$\Theta(t,L_i)$: 第$i$层神经元所有$t$-路覆盖组合</p>
<p>$\theta \in \Theta(t,L_i)$：是$t$个神经元的集合，拥有$2^t$种激活配置</p>
<p>$\Theta_{Full}(t,L_i,T) \subseteq \Theta(t,L_i)$：能被$T$完全覆盖的$t$-路覆盖组合</p>
<h3 id="t-路组合稀疏覆盖"><a href="#t-路组合稀疏覆盖" class="headerlink" title="$t$-路组合稀疏覆盖"></a>$t$-路组合稀疏覆盖</h3><p>$T$的组合稀疏覆盖=覆盖了所有神经元配置的组合数 / 所有组合数</p>
<p>例子：</p>
<p><img src="/2020/08/20/DeepCT/fig1.png" alt="fig1" style="zoom:60%;"></p>
<p>$L_i$层中共有4个神经元${n1,n2,n3,n4}$，<br>2-路组合共有六种：$\{n1,n2\}，\{n1,n3\}，\{n1,n4\}，\{n2,n3\}，\{n2,n4\}，\{n3,n4\}$<br>每个2-路组合有四种神经元激活配置$(0，0)、(0，1)、(1，0)$和$(1，1)$<br>在6个双向组合中，T只覆盖了$\{n1，n2\}，\{n1，n4\}，\{n2，n3\}$和$\{n3，n4\}$的四种神经元激活配置(只有这四个组合出现了四种神经元激活配置)<br>则Li层的2-路组合稀疏覆盖率$= 4 / 6= 66.6\%$</p>
<p>由于$t$-路组合稀疏覆盖不能考虑每个神经元组合内的覆盖，接下来我们引入t-way组合稠密覆盖。</p>
<h3 id="t-路组合稠密覆盖"><a href="#t-路组合稠密覆盖" class="headerlink" title="$t$-路组合稠密覆盖"></a>$t$-路组合稠密覆盖</h3><p>$T$的组合稀疏覆盖= 被覆盖了的激活配置数 / 所有组合的所有激活配置数目</p>
<p>例子：同上图</p>
<p>由于$L_i$中有六个神经元的双向组合，并且每个组合有四个神经元激活配置,总共有24种激活配置</p>
<p>测试集T可以覆盖20种配置，未覆盖的神经元激活配置为$\{n1，n3\}=(0，1)，\{n1，n3\}=(1，0)，\{n2，n4\}=(0，1)，\{n2，n4\}=(1，0)$,因此，T的双向组合密集覆盖率为83.3%。</p>
<h3 id="p-t-完备性"><a href="#p-t-完备性" class="headerlink" title="$(p,t)$完备性"></a>$(p,t)$完备性</h3><p>达到$p$(百分比)覆盖的组合比例</p>
<p>例子：同上图</p>
<p>在神经元的双向组合中，$\{n1，n2\}，\{n1，n4\}，\{n2，n3\}，\{n3，n4\}$的覆盖双向构型比为100%，$\{n1，n3\}$和$\{n2，n4\}$的覆盖双向构型比为50%。则$L_i$的(0.5，2)-完备性为100%，$L_i$的(1，2)-完备性为66.6%。即达到100%覆盖的有4个,达到50%以上覆盖的有6个。</p>
<h2 id="DNN的鲁棒性测试"><a href="#DNN的鲁棒性测试" class="headerlink" title="DNN的鲁棒性测试"></a>DNN的鲁棒性测试</h2><h3 id="d-局部鲁棒性"><a href="#d-局部鲁棒性" class="headerlink" title="$d$-局部鲁棒性"></a>$d$-局部鲁棒性</h3><script type="math/tex; mode=display">\forall x':\parallel x'-x \parallel \leq d \Rightarrow C(x) = C(x')</script><p>约束：$L_{\infty}-norm$</p>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p><img src="/2020/08/20/DeepCT/al.png" alt="al" style="zoom:67%;"></p>
<ul>
<li>输入<ul>
<li>DNN</li>
<li>$t$:测试粒度，每个组合内神经元个数</li>
<li>组合测试标准</li>
<li>初始种子集合</li>
</ul>
</li>
<li>输出<ul>
<li>正确样本集合</li>
<li>对抗样本集合</li>
</ul>
</li>
<li>测试用例生成方法<ul>
<li>没有特殊规定，<font color="red">基于搜索、覆盖率引导的随机测试、符号分析/约束求解都可以</font></li>
<li>本文实验：DNN使用ReLU激活函数，约束求解方法（Cplex solver）生成测试用例<ul>
<li><font color="red">即将CT覆盖目标编码为目标的线性约束，使种子输入的$L_{\infty}$-范数扰动距离最小。</font>



</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul>
<li>数据集和模型<ul>
<li>MNIST和两个预训练好的DNN模型DNN1和DNN2（结构和精度略）</li>
</ul>
</li>
<li>从原测试集随机选择1000个样本作为初始种子，<font color="red">且这1000个都能被原DNN正确分类</font></li>
<li>随机测试（Random Testing)<ul>
<li><font color="red">随机生成10000个测试用例（如何随机生成的？）</font>，然后检测健壮性问题</li>
<li>实验结果：RT已经能够检测到DNN1上的194个样本和DNN2上的178个样本的健壮性问题，总共266个独特的问题，其中106个是DNN1和DNN2上共同的问题。</li>
</ul>
</li>
<li>DeepCT测试<ul>
<li>1000个样本中去掉266个随机测试已经发现问题的样本，剩余的734个样本中随机采样50个进一步分析$d$-局部鲁棒性（$d$设为0.15，使用2-路CT标准）</li>
<li>实验结果：<ul>
<li>生成图片数量相当的情况下，DeepCT达到的覆盖率远超随机测试</li>
<li>随着测试层数和生成的测试用例增加，覆盖率也逐渐增加</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/2020/08/20/DeepCT/fig2.png" alt="fig2" style="zoom:60%;"></p>
<h2 id="可控制参数-变量总结"><a href="#可控制参数-变量总结" class="headerlink" title="可控制参数/变量总结"></a>可控制参数/变量总结</h2><ul>
<li>$t$：覆盖粒度</li>
<li>$d$：鲁棒性约束</li>
<li>$L_{\infty}$约束的参数</li>
<li>初始种子集合</li>
<li>$p$：完备性指标</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1] <a href="https://blog.csdn.net/qq_33935895/article/details/105454414">https://blog.csdn.net/qq_33935895/article/details/105454414</a></p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>DNN测试</tag>
        <tag>测试输入生成</tag>
        <tag>测试标准</tag>
        <tag>组合测试</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】DLFuzz</title>
    <url>/2020/08/20/DLFuzz/</url>
    <content><![CDATA[<p>原文：DLFuzz: Differential Fuzzing Testing of Deep Learning Systems （ESEC/FSE’18）<a id="more"></a></p>
<p>代码：<a href="https://github.com/turned2670/DLFuzz">https://github.com/turned2670/DLFuzz</a> </p>
<h2 id="可控制变量及参数总结"><a href="#可控制变量及参数总结" class="headerlink" title="可控制变量及参数总结"></a>可控制变量及参数总结</h2><ul>
<li>输入集合（未标注）</li>
<li>待测试DNN</li>
<li>$k$：除原预测标签外，top-k个其他标签</li>
<li>$m$：欲覆盖的神经元个数</li>
<li><p>strategies：神经元选择策略</p>
<ul>
<li><p>策略1：选择过去测试中常被覆盖的神经元</p>
</li>
<li><p>策略2：选择过去测试中极少被覆盖到的神经元</p>
</li>
<li><p>策略3：选择权重高的神经元</p>
</li>
<li>策略4：选择激活阈值附近的神经元</li>
</ul>
</li>
<li>$\lambda$：平衡两个目标（预测类别差异和覆盖新的神经元）的参数</li>
<li>predict_weight：代码里在上公式中$\sum c_i$前的权重，默认为0.5（未在论文里出现的参数）</li>
<li>iter_times: 每个种子的迭代次数</li>
<li>threshold: 神经元激活阈值</li>
<li>learning_step：步长，代码里设为0.02</li>
</ul>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><ul>
<li><p>梯度约束：<font color="red">论文里说可以加保持符号约束或DeepXplore里的约束，但代码似乎没加任何约束，直接在输入上增加梯度*步长</font></p>
</li>
<li><p>生成图像距离约束：满足L2距离（&lt;0.02）（计算方式为L2_norm / orig_L2_norm）</p>
</li>
<li><p>约束：一个输入能提升的神经元覆盖率随着时间的增加而下降，对应的保留种子的阈值也随着运行时间的增加而降低<font color="red">（代码里体现为保留种子时最少需要提升的覆盖率随迭代次数增加而降低）</font></p>
<p><img src="/2020/08/20/DLFuzz/fig1.png" alt="fig1" style="zoom: 80%;"></p>
</li>
</ul>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集和模型"><a href="#数据集和模型" class="headerlink" title="数据集和模型"></a>数据集和模型</h3><p>MNIST（LeNet-1, LeNet-4, LeNet-5）和ImageNet（VGG-16, VGG-19, ResNet50）</p>
<font color="red">与DeepXplore相同</font>

<h3 id="默认参数设置"><a href="#默认参数设置" class="headerlink" title="默认参数设置"></a>默认参数设置</h3><ul>
<li><p>随机选择20个初始输入<font color="red">（类别是否平衡？20是否过少？）</font></p>
</li>
<li><p>$k=4,m=10$，strategy为策略1，iter_times=3 </p>
</li>
</ul>
<h3 id="实验1：DLFuzz与DeepXplore比较"><a href="#实验1：DLFuzz与DeepXplore比较" class="headerlink" title="实验1：DLFuzz与DeepXplore比较"></a>实验1：DLFuzz与DeepXplore比较</h3><ul>
<li><p>实验方法：对相同的20个初始输入，比较DLFuzz相对DeepXplore神经元覆盖率、l2距离、生成对抗样本的个数、每个对抗样本平均生成时间</p>
</li>
<li><p>实验结果：</p>
<ul>
<li><p>覆盖率提升<font color="red">（DLFuzz的优化目标选择了10个神经元，DeepXplore只选了一个）</font></p>
</li>
<li><p>L2距离很小，生成的扰动更隐秘<font color="red">（DeepXplore未对距离做限制，甚至认为L1距离越大多样性越好）</font></p>
</li>
<li><p>生成对抗样本数量更多（DeepXplore对每组DNN每张图片最多只生成一个对抗样本，DLFuzz每个模型每张图片可以生成多个对抗样本）</p>
</li>
<li><p>更短的时间消耗（除了ResNet50，因为神经元数量大所以选择神经元的耗时长）</p>
</li>
</ul>
</li>
</ul>
<p><img src="/2020/08/20/DLFuzz/fig2.png" alt="fig2" style="zoom:67%;"></p>
<h3 id="实验2：四种神经元选择策略比较"><a href="#实验2：四种神经元选择策略比较" class="headerlink" title="实验2：四种神经元选择策略比较"></a>实验2：四种神经元选择策略比较</h3><ul>
<li><p>实验方法：比较四种策略和DeepXplore，随着测试图片生成数量增多，神经元覆盖率的增长趋势</p>
</li>
<li><p>实验结果：策略1略好<font color="red">（生成数量是否过少？19张神经元覆盖率就趋于平缓）</font></p>
<p><img src="/2020/08/20/DLFuzz/fig3.png" alt="fig3" style="zoom:60%;"></p>
</li>
</ul>
<h3 id="实验3：用生成图片重新训练"><a href="#实验3：用生成图片重新训练" class="headerlink" title="实验3：用生成图片重新训练"></a>实验3：用生成图片重新训练</h3><ul>
<li>实验方法：用生成的114个对抗样本重新训练MNIST的三个DNN模型，平均提升准确率1.8%<font color="red">（太少？）</font></li>
</ul>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>DNN测试</tag>
        <tag>模糊测试</tag>
        <tag>测试输入生成</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】DeepConcolic</title>
    <url>/2020/08/19/DeepConcolic/</url>
    <content><![CDATA[<p>原文：Concolic Testing for Deep Neural Networks （ASE’18) <a id="more"></a></p>
<p>代码地址：<a href="https://github.com/TrustAI/DeepConcolic">https://github.com/TrustAI/DeepConcolic</a> （利普希茨覆盖测试部分用MATLAB写的）</p>
<h2 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h2><ul>
<li>提出了第一种DNN的Concolic测试方法。通过具体执行获得激活模式，通过反转神经元的值，优化得到变换后的输入（类似约束求解器）。使测试集达到高覆盖率。</li>
<li><p>提出利普希茨常数覆盖标准。</p>
</li>
<li><p>与其他方法比较：</p>
</li>
</ul>
<p><img src="/2020/08/19/DeepConcolic/compare.png" alt="compare"></p>
<font color="red">（DeepTest中的Jaccard距离并不是用来约束图片距离的，只是比较激活神经元的差异）</font>

<h2 id="形式化定义"><a href="#形式化定义" class="headerlink" title="形式化定义"></a>形式化定义</h2><h3 id="激活模式"><a href="#激活模式" class="headerlink" title="激活模式"></a>激活模式</h3><p>$ap[t]_{k,l} \in \{true,false\}$ 表示输入$t$的第$k$层第$l$个神经元是否被$ReLU$函数激活。</p>
<h3 id="覆盖要求"><a href="#覆盖要求" class="headerlink" title="覆盖要求"></a>覆盖要求</h3><p>略，公式较多但比较好理解，逻辑形式表达覆盖标准。</p>
<h3 id="覆盖要求的可满足性"><a href="#覆盖要求的可满足性" class="headerlink" title="覆盖要求的可满足性"></a>覆盖要求的可满足性</h3><p>给定一组测试用例$T$和覆盖要求$r$  ，$T \vDash r$表示测试用例满足了覆盖要求。</p>
<h3 id="覆盖要求的复杂度"><a href="#覆盖要求的复杂度" class="headerlink" title="覆盖要求的复杂度"></a>覆盖要求的复杂度</h3><p>检查$T \vDash r$需要能在多项式时间内完成。</p>
<h3 id="覆盖率"><a href="#覆盖率" class="headerlink" title="覆盖率"></a>覆盖率</h3><p>给定一个覆盖要求的集合$R$,测试用例集$T$可满足要求的数量所占比例即覆盖率。</p>
<h2 id="特定覆盖要求介绍"><a href="#特定覆盖要求介绍" class="headerlink" title="特定覆盖要求介绍"></a>特定覆盖要求介绍</h2><p>本节用上面的方法形式化定义了目前学术界已有的一些覆盖标准。</p>
<h3 id="利普希茨连续条件（Lipschitz-Continuity）"><a href="#利普希茨连续条件（Lipschitz-Continuity）" class="headerlink" title="利普希茨连续条件（Lipschitz Continuity）"></a>利普希茨连续条件（Lipschitz Continuity）</h3><p>对一个神经网络$N$，若存在$c\geq0$，使得对输入样本集合$D_{L1}$中的任意两个样本$x_1$、$x_2$，满足：</p>
<script type="math/tex; mode=display">\parallel v[x_1]_1-v[x_2]_1 \parallel \leq c \cdot \parallel x_1-x_2 \parallel</script><p>其中$v[x]_1$表示<font color="red">输入层</font>神经元的激活向量（？），$c$为利普希茨常数。满足条件的最小的$c$称为最佳利普希茨常数$c_{best}$。</p>
<p>利普希茨覆盖：是一组覆盖要求的集合，要求体现了给定输入子空间中的任意两个输入$x_1$、$x_2$满足上述利普希茨连续条件的情况</p>
<h3 id="神经元覆盖率（NC）"><a href="#神经元覆盖率（NC）" class="headerlink" title="神经元覆盖率（NC）"></a>神经元覆盖率（NC）</h3><p>DeepXplore中定义的神经元覆盖率，形式化表示为一组覆盖标准：</p>
<p>$\{\exists x.ap[x]_{k,i}=true|2\leq k \leq K-1,1 \leq i \leq s_k\}$</p>
<p>即对每个神经元提出一个覆盖要求——存在输入x能将其激活。</p>
<h3 id="MC-DC覆盖率（SS-coverage）"><a href="#MC-DC覆盖率（SS-coverage）" class="headerlink" title="MC/DC覆盖率（SS coverage）"></a>MC/DC覆盖率（SS coverage）</h3><p>DeepCover提出，</p>
<h3 id="神经元边缘覆盖率（NBC）"><a href="#神经元边缘覆盖率（NBC）" class="headerlink" title="神经元边缘覆盖率（NBC）"></a>神经元边缘覆盖率（NBC）</h3><p>DeepGauge中提出，</p>
<h2 id="本文方法"><a href="#本文方法" class="headerlink" title="本文方法"></a>本文方法</h2><h3 id="算法概览"><a href="#算法概览" class="headerlink" title="算法概览"></a>算法概览</h3><p><img src="/2020/08/19/DeepConcolic/overview.png" alt="overview" style="zoom:80%;"></p>
<p><img src="/2020/08/19/DeepConcolic/算法.png" alt="算法" style="zoom:60%;"></p>
<ul>
<li>输入<ul>
<li>一个DNN $N$</li>
<li>一个输入样本$t_0$</li>
<li>一组覆盖要求$R$</li>
<li>启发式$\delta$：<font color="red">与选择的覆盖要求有关，使得第7行能尽可能找到一组容易满足的要求</font></li>
</ul>
</li>
<li>输出：<ul>
<li>一组测试样本$T$，最初只包含$t_0$</li>
</ul>
</li>
<li><p>validity_check函数：检查$t’$是否有效</p>
</li>
<li><p>当$R$中所有要求被满足或不能满足$R$中的其他要求时算法停止</p>
</li>
</ul>
<h3 id="要求评估（requirement-evaluation函数，具体执行部分"><a href="#要求评估（requirement-evaluation函数，具体执行部分" class="headerlink" title="要求评估（requirement_evaluation函数，具体执行部分)"></a>要求评估（requirement_evaluation函数，具体执行部分)</h3><ul>
<li><p>寻找一组$(t,r)$，使得$t$变换成$t’$后最有可能满足要求$r$。</p>
</li>
<li><p>定义$arg max_x a:e$ ：满足布尔表达式$e$的所有样本里，使得算数表达式$a$最大的$x$</p>
</li>
<li><p>启发式：略，得到使得覆盖要求表达式（即前面的四种覆盖率）值取到最大的样本</p>
<ul>
<li>利普希茨连续</li>
<li>NC</li>
<li>SSC</li>
<li>NBC</li>
</ul>
</li>
</ul>
<h3 id="符号分析（symbolic-analysis函数）"><a href="#符号分析（symbolic-analysis函数）" class="headerlink" title="符号分析（symbolic_analysis函数）"></a>符号分析（symbolic_analysis函数）</h3><p>根据$(t,r)$变换$t$生成$t’$，有三种方法：</p>
<h4 id="1、利用线性编程进行符号分析"><a href="#1、利用线性编程进行符号分析" class="headerlink" title="1、利用线性编程进行符号分析"></a>1、利用线性编程进行符号分析</h4><p>将DNN实例$N(x)$映射到可以使用线性编程(LP)建模的激活模式$ap[x]$，并根据不同覆盖准则定义新的激活模式$ap’[x]$:</p>
<ul>
<li>NC：反转某神经元$n_{k,i}$的值，保持第$k$层之前的层的输出不变，因为该神经元只受之前层的影响。之后层的输出不用管。</li>
<li>SSC：反转$n_{k+1,j}$和$n_{k,i}$</li>
<li>NBC：目标使得神经元$n_{k,i}$的激活值超过其上界或低于其下界</li>
</ul>
<p>LP模型将对$ap’[x]$进行编码并求解满足要求$r$的输入$t’$</p>
<h4 id="2、基于全局优化的符号分析"><a href="#2、基于全局优化的符号分析" class="headerlink" title="2、基于全局优化的符号分析"></a>2、基于全局优化的符号分析</h4><p>基于全局优化算法达到上述目标生成$t’$</p>
<h4 id="3、Lipschitz测试用例生成"><a href="#3、Lipschitz测试用例生成" class="headerlink" title="3、Lipschitz测试用例生成"></a>3、Lipschitz测试用例生成</h4><p>本文提出了一种新颖的交替式罗盘搜索方案（略）</p>
<h3 id="测试预言（约束）"><a href="#测试预言（约束）" class="headerlink" title="测试预言（约束）"></a>测试预言（约束）</h3><p>给定实数$b$，如果测试用例$t’ \in T$满足：</p>
<script type="math/tex; mode=display">\parallel t-t' \parallel \leq b</script><p>则称$t’$为有效的。若$t$与$t’$的预测结果一致，则称DNN通过了测试预言。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul>
<li>时间限制：12h</li>
<li>所有覆盖结果均运行10次以上取平均</li>
</ul>
<h3 id="实验1：与DeepXplore对比"><a href="#实验1：与DeepXplore对比" class="headerlink" title="实验1：与DeepXplore对比"></a>实验1：与DeepXplore对比</h3><ul>
<li><p>数据集：MNIST、CIFAR-10</p>
</li>
<li><p>实验方法</p>
<ul>
<li>从随机采样的初始种子集合开始</li>
<li>DeepXplore要求多个模型差分测试：采用目标测试的DNN模型+DeepXplore论文里的2个模型</li>
<li>比较二者达到的覆盖率</li>
</ul>
</li>
<li><p>实验结果</p>
<p><img src="/2020/08/19/DeepConcolic/ex1.png" alt="ex1" style="zoom:70%;"></p>
<ul>
<li>DeepConcolic能达到比DeepXplore更高的覆盖率</li>
<li>但DeepXplore更快，几秒内运行结束<font color="red">（没有说DeepConcolic的运行时间）</font></li>
<li>生成的图像：<font color="red">(几乎完全反相也符合约束？)</font></li>
</ul>
<p><img src="/2020/08/19/DeepConcolic/ex1-2.png" alt="ex1-2" style="zoom:67%;"></p>
</li>
</ul>
<h3 id="实验2：比较NC-SCC和NBC"><a href="#实验2：比较NC-SCC和NBC" class="headerlink" title="实验2：比较NC, SCC和NBC"></a>实验2：比较NC, SCC和NBC</h3><ul>
<li><p>实验方法</p>
<ul>
<li>NC：从一张初始种子开始</li>
<li>SCC和NBC：初始集合包含1000张图片，且仅测试一部分神经元<font color="red">（和NC差别很大）</font></li>
<li>设置$L _\infty$的距离上界为0.3，$L_0$的距离上界为100个像素</li>
</ul>
</li>
<li><p>实验结果</p>
<p><img src="/2020/08/19/DeepConcolic/MyBlog\source\_posts\DeepConcolic\ex2-1.png" alt="ex2-1" style="zoom:70%;"></p>
<p><img src="/2020/08/19/DeepConcolic/ex2-3.png" alt="ex2-3"></p>
<ul>
<li><p>使用全局优化进行符号分析的开销太高。因此，具有$L_0$范数的SSC结果被排除在外。<font color="red">(?右图没有蓝色条形)</font></p>
</li>
<li><p>总体而言，DeepConcolic实现了高覆盖率，并使用健壮性检查检测到大量的对抗性示例。然而，NBC的覆盖范围是有限的</p>
</li>
<li><p>concolic测试可以发现距离极小的对抗样本：如1255≈0.0039（$L_{\infty}$范数），1像素（$L_0$范数）</p>
</li>
<li><p>对抗样本的平均距离：(对于同一网络，当距离度量改变时，使用NC发现的对抗性示例的数量可能会有很大变化。在设计DNN的覆盖标准时，需要使用各种距离度量来检查它们。)</p>
<p><img src="/2020/08/19/DeepConcolic/ex2-2.png" alt="ex2-2" style="zoom:67%;"></p>
</li>
</ul>
</li>
</ul>
<h3 id="实验3：利普希茨常数检验结果"><a href="#实验3：利普希茨常数检验结果" class="headerlink" title="实验3：利普希茨常数检验结果"></a>实验3：利普希茨常数检验结果</h3><p><img src="/2020/08/19/DeepConcolic/ex3-1.png" alt="ex3-1" style="zoom:80%;"></p>
<ul>
<li>我们通过随机测试生成的方式产生了100万个测试对，但最大Lipschitz转换率只达到了3.23，并且大多数测试对都在[0.01，2]的范围内。另一方面，我们的Concolic方法可以覆盖[0.01，10.38]的Lipschitz范围，其中大多数情况位于[3.5，10]，而随机测试生成很难覆盖这一范围。</li>
<li>目标：覆盖较大Lipschitz常数范围。如对于自动驾驶汽车等安全关键应用，Lipschitz常数较大的DNN本质上表明它更容易受到对手的扰动。因此，可以覆盖较大Lipschitz常数的测试方法为训练的DNN提供了有用的鲁棒性指标。我们认为，对于DNNs的安全测试，Lipschitz常数覆盖的Concolic测试方法可以补充现有的方法来实现更好的覆盖。</li>
</ul>
<h2 id="可控制参数和变量总结"><a href="#可控制参数和变量总结" class="headerlink" title="可控制参数和变量总结"></a>可控制参数和变量总结</h2><ul>
<li>初始样本集合</li>
<li>覆盖标准：利普希茨常数覆盖、NC、NBC、SSC</li>
<li>变换约束条件（$L_\infty$、$L_0$及其参数）</li>
<li>测试的神经元（全部还是部分）</li>
</ul>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>DNN测试</tag>
        <tag>测试输入生成</tag>
        <tag>Concolic测试</tag>
      </tags>
  </entry>
  <entry>
    <title>DNN测试输入生成论文可控制参数及变量总结</title>
    <url>/2020/08/20/Variables-Comparison/</url>
    <content><![CDATA[<a id="more"></a>
<h2 id="共同参数或变量总结"><a href="#共同参数或变量总结" class="headerlink" title="共同参数或变量总结"></a>共同参数或变量总结</h2><ul>
<li>初始输入种子集合相关变量<ul>
<li>数量：1个到几千个不等</li>
<li>采样方式：均为随机<ul>
<li>DeepXplore还要求了<strong>类别平衡</strong></li>
</ul>
</li>
<li>是否标注<ul>
<li>若已标注，是否要求<strong>初始预测结果正确</strong>（DeepCT要求了）</li>
<li>未标注（DeepXplore要求其使用的多个模型预测一致，DLFuzz）</li>
</ul>
</li>
</ul>
</li>
<li>测试标准/覆盖率相关变量<ul>
<li>计算方式<ul>
<li>DeepTest中修改了卷积层神经元覆盖率的计算方式：输出特征图的平均值与激活阈值做比较</li>
</ul>
</li>
<li>神经元覆盖率采用的激活阈值<ul>
<li>原算法：将所有输出值缩放到[0,1]，然后设置阈值（<font color="red">离群点等会否导致不同数据集阈值差距很不同</font>）</li>
<li>DeepXplore中用过多种阈值（0、0.25、0.75等），后人多数用的0，也有0.75等</li>
</ul>
</li>
<li>覆盖神经元集合的选择：<ul>
<li>多数选择所有层的神经元</li>
<li>个别选择去掉一些层<ul>
<li>如DeepXplore测试达到100%覆盖率所用的时间时去掉了全连接层<font color="red">（但覆盖全连接层意义应该更大？）</font></li>
<li>TensorFuzz要求用户自己选择层</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>图像上增加的扰动相关变量</p>
<ul>
<li>扰动生成方式<ul>
<li>基于梯度优化</li>
<li>基于覆盖率引导的模糊测试</li>
<li>基于约束求解</li>
<li>基于搜索</li>
</ul>
</li>
<li>扰动种类<ul>
<li>DeepTest说不同种类变换能激活不同神经元（<font color="red">存疑</font>）</li>
</ul>
</li>
<li>扰动位置：<ul>
<li>DeepXplore中的单个矩形位置由用户提前设定，多个黑色矩形的位置随机</li>
</ul>
</li>
<li>扰动大小：<ul>
<li>DeepXplore中的矩形大小由用户提前设定（与数据集图像大小有关）</li>
</ul>
</li>
<li>扰动约束条件：<ul>
<li>$L_0-norm$<ul>
<li>如DeepCheck（识别重要像素攻击）</li>
</ul>
</li>
<li>$L_1-norm$<ul>
<li>DeepXplore未对距离做限制，甚至认为$L_1$距离越<strong>大</strong>多样性越好</li>
</ul>
</li>
<li>$L_2-norm$<ul>
<li>如DLFuzz：满足L2距离（&lt;0.02）（计算方式为L2_norm / orig_L2_norm）</li>
</ul>
</li>
<li>$L\infty-norm$<ul>
<li>如TensorFuzz</li>
</ul>
</li>
<li>平衡$L_0$和$L\infty-norm$<ul>
<li>如DeepHunter采用的</li>
</ul>
</li>
<li>约束MSE（DeepTest)：$|MSE(trans,param)-MSE_{org}|\leq \epsilon$ <font color="red">(用到了oracle)</font></li>
</ul>
</li>
</ul>
</li>
<li><p>模糊测试相关变量（DLFuzz、TensorFuzz、DeepHunter、DeepTest）</p>
<ul>
<li>判断种子是否应该保留在队列时最少需提升的覆盖率</li>
<li>每个种子的迭代次数</li>
<li>从队列中优先挑选哪些种子的策略<ul>
<li>随机</li>
<li>选择新鲜的</li>
<li>平衡新鲜和多样性</li>
</ul>
</li>
</ul>
</li>
<li>优化算法相关变量<ul>
<li>优化目标选择需要新激活的神经元个数？</li>
</ul>
</li>
<li>其他<ul>
<li>每个种子生成对抗样本的个数<ul>
<li>有的方法只生成一张，有的多张</li>
</ul>
</li>
<li>蜕变关系<ul>
<li>图像分类问题：扰动满足约束的情况下，预测类别应该不变</li>
<li>回归问题：<ul>
<li>DeepTest：因为只测试了Driving数据集（回归问题），使用MSE判断蜕变关系是否满足$(\theta_i-\theta_{ti}) \leq \lambda MSE_{orig}$</li>
<li>DeepRoad：没有使用MSE，直接比较输出结果是否小于阈值$\epsilon$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="测试输入生成类论文总结"><a href="#测试输入生成类论文总结" class="headerlink" title="测试输入生成类论文总结"></a>测试输入生成类论文总结</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">文章名</th>
<th style="text-align:left">可控制参数/变量总结</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">DeepXplore<br>(SOSP’17)</td>
<td style="text-align:left"><img src="/2020/08/20/Variables-Comparison/DeepXplore.png" alt="DeepXplore"></td>
</tr>
<tr>
<td style="text-align:center">TensorFuzz<br>(ICML’19)</td>
<td style="text-align:left"><img src="/2020/08/20/Variables-Comparison/TensorFuzz.png" alt="TensorFuzz" style="zoom:80%;"></td>
</tr>
<tr>
<td style="text-align:center">DeepTest<br>(ICSE’18)</td>
<td style="text-align:left"><img src="/2020/08/20/Variables-Comparison/DeepTest.png" alt="DeepTest" style="zoom:80%;"></td>
</tr>
<tr>
<td style="text-align:center">DLFuzz<br>(ESEC/FSE’18)</td>
<td style="text-align:left"><img src="/2020/08/20/Variables-Comparison/DLFuzz.png" alt="DLFuzz" style="zoom: 80%;"></td>
</tr>
<tr>
<td style="text-align:center">DeepHunter<br>（ISSTA’19）</td>
<td style="text-align:left"><img src="/2020/08/20/Variables-Comparison/DeepHunter.png" alt="DeepHunter" style="zoom:80%;"></td>
</tr>
<tr>
<td style="text-align:center">DeepConcolic<br>（ASE’18）</td>
<td style="text-align:left"><img src="/2020/08/20/Variables-Comparison/DeepConcolic.png" alt="DeepConcolic" style="zoom: 80%;"></td>
</tr>
<tr>
<td style="text-align:center">DeepCT<br>(SANER’19)<br><font color="red">(未找到代码)</font></td>
<td style="text-align:left"><img src="/2020/08/20/Variables-Comparison/DeepCT.png" alt="DeepCT" style="zoom: 80%;"></td>
</tr>
<tr>
<td style="text-align:center">DeepCheck<br>（ISSRE’18）<br><font color="red">(未找到代码)</font></td>
<td style="text-align:left"><img src="/2020/08/20/Variables-Comparison/MyBlog\source\_posts\Variables-Comparison\DeepCheck.png" alt="DeepCheck" style="zoom: 80%;"></td>
</tr>
<tr>
<td style="text-align:center">DeepRoad<br>（ASE’18）<br><font color="red">(未找到代码)</font></td>
<td style="text-align:left"><img src="/2020/08/20/Variables-Comparison/DeepRoad.png" alt="DeepRoad" style="zoom:80%;"></td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>科研笔记</category>
      </categories>
      <tags>
        <tag>DNN测试</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文笔记】DeepXplore</title>
    <url>/2020/08/19/DeepXplore/</url>
    <content><![CDATA[<p>原文：DeepXplore: Automated Whitebox Testing of Deep Learning Systems（SOSP’17）<a id="more"></a></p>
<p>代码地址：<a href="https://github.com/peikexin9/deepxplore">https://github.com/peikexin9/deepxplore</a></p>
<h2 id="可控制参数或变量"><a href="#可控制参数或变量" class="headerlink" title="可控制参数或变量"></a>可控制参数或变量</h2><ul>
<li><p>种子输入集合数量 (类别均衡，随机选择，<u>约束：所有DNN模型必须对每个种子的初始预测结果相同</u>)</p>
</li>
<li><p>多个DNN</p>
</li>
<li><p>$\lambda_1$：平衡其他DNN和被选中DNN预测的差别（$\lambda_1$越大，选中DNN预测为原类别c的概率越低，$\lambda_1$越小，越能维持其他DNN的预测结果）</p>
<p><img src="/2020/08/19/DeepXplore/1.png" alt="公式1"></p>
</li>
<li><p>$\lambda_2$：平衡两个优化目标大小（即预测差异和神经元覆盖率，$\lambda_2$越大，越关注覆盖更多神经元，否则更关注生成预测差异图片）</p>
</li>
</ul>
<p><img src="/2020/08/19/DeepXplore/2.png" alt="公式2"></p>
<ul>
<li>$s$: 梯度下降步长（$s$过大可能会导致极小值附近震荡，$s$过小导致迭代次数多）</li>
<li>$t$: 神经元覆盖率阈值（$t$越大，达到覆盖率目标越难）</li>
<li>$p$: 覆盖率目标</li>
<li>梯度下降迭代最大次数（代码里）</li>
<li><font color="red">在每次迭代的梯度$G$上施加的真实领域约束:</font><ul>
<li>（1）不同亮度模拟光照：$G$被$mean(G)$ 取代</li>
<li>（2）单个矩形($m*n$大小)模拟意外或故意遮挡：<ul>
<li>选择矩形左上顶点所在的位置$(i,j)$，将$G_{i:i+m,j:j+n}$施加于原图相应位置。</li>
<li><font color="red">$m$、$n$的大小和$(i,j)$为自定义的参数，迭代多次都在相同位置</font></li>
</ul>
</li>
<li>（3） 多个随机黑色小矩形模拟镜头污垢<ul>
<li>位置随机的若干个$m*m$大小的黑色矩形<font color="red">（每次迭代位置不同，$m$值自定义，与数据集图片大小有关）</font></li>
<li>如果$mean(G_{i:i+m,j:j+m})$，则图片不动，否则变黑（即只允许降低像素值）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p><img src="/2020/08/19/DeepXplore/算法.png" alt="算法" style="zoom:80%;"></p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集和模型"><a href="#数据集和模型" class="headerlink" title="数据集和模型"></a>数据集和模型</h3><p><img src="/2020/08/19/DeepXplore/dataset.png" alt="dataset"></p>
<h3 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h3><ul>
<li>种子输入集合：随机从测试集选择2000个输入（保持<font color="red">类别平衡</font>，满足所有DNN预测结果相同的约束）</li>
<li>参数$\lambda_1,\lambda_2,s,t$</li>
</ul>
<p><img src="/2020/08/19/DeepXplore/para.png" alt="para" style="zoom:67%;"></p>
<h3 id="实验1：神经元覆盖率的优势"><a href="#实验1：神经元覆盖率的优势" class="headerlink" title="实验1：神经元覆盖率的优势"></a>实验1：神经元覆盖率的优势</h3><h4 id="实验1-1：神经元覆盖率与代码覆盖率比较"><a href="#实验1-1：神经元覆盖率与代码覆盖率比较" class="headerlink" title="实验1-1：神经元覆盖率与代码覆盖率比较"></a>实验1-1：神经元覆盖率与代码覆盖率比较</h4><ul>
<li><p>实验方法：随机选择10个测试输入，测量代码覆盖率和神经元覆盖率大小</p>
</li>
<li><p>参数设置：设置$t=0.75$（神经元激活阈值，<font color="red">按比例缩放至[0,1]区间，不同DNN阈值区别很大？）前面都设的0，故意设大t凸显结果差异）</font></p>
</li>
<li><p>实验结果：少量测试输入即可达到100%代码覆盖率，但神经元覆盖率最多只有34%：</p>
<p><img src="/2020/08/19/DeepXplore/ex1-1.png" alt="ex1-1" style="zoom:80%;"></p>
</li>
</ul>
<h4 id="实验1-2：神经元覆盖率对DeepXplore生成能导致预测差异样本的作用"><a href="#实验1-2：神经元覆盖率对DeepXplore生成能导致预测差异样本的作用" class="headerlink" title="实验1-2：神经元覆盖率对DeepXplore生成能导致预测差异样本的作用"></a>实验1-2：神经元覆盖率对DeepXplore生成能导致预测差异样本的作用</h4><ul>
<li>实验方法：从MNIST测试集随机选择2000种子输入，分别设置$\lambda_2$为1和0（$\lambda_2=0$时优化目标里不考虑覆盖新的神经元）。测量生成预测差异样本（difference-inducing inputs）的多样性<strong>（平均$L_1$距离：改变前后像素值之差的和，<font color="red">是否适合作为衡量多样性的指标？</font>）</strong></li>
<li>参数设置：$t=0.25$</li>
<li>实验结果：神经元覆盖率帮助提升了生成样本的多样性<font color="red">（①神经元覆盖率NC提升并不明显？作者的解释是NC很高的情况下，NC的一点点提升就能带来多样性的大幅提升。②生成数量#Diffs减少了：作者的解释是设置$\lambda_2=1$后更倾向于生成不同输入而不是提高输入数量，作者认为生成数量并不是一个好的衡量生成样本的方式）</font></li>
</ul>
<p><img src="/2020/08/19/DeepXplore/ex1-2.png" alt="ex1-2" style="zoom:75%;"></p>
<h4 id="实验1-3：不同类别输入对激活神经元的影响"><a href="#实验1-3：不同类别输入对激活神经元的影响" class="headerlink" title="实验1-3：不同类别输入对激活神经元的影响"></a>实验1-3：不同<strong><em>类别</em></strong>输入对激活神经元的影响</h4><ul>
<li>实验方法：MNIST数据集的LeNet-5模型，运行100对相同类别（如类别8）图片，和100对不同类别（如类别8和类别4）图片，测量平均激活神经元个数和共同激活神经元的个数（overlap）。</li>
<li>实验结果：相同类别共同激活的平均神经元个数$&gt;$不同类别。神经元覆盖率可以有效地估计DNN测试中激活的不同规则的数量。</li>
</ul>
<p><img src="/2020/08/19/DeepXplore/ex1-3.png" alt="ex1-3" style="zoom:80%;"></p>
<h3 id="实验2：DeepXplore的效果"><a href="#实验2：DeepXplore的效果" class="headerlink" title="实验2：DeepXplore的效果"></a>实验2：DeepXplore的效果</h3><h4 id="实验2-1：DeepXplore在神经元覆盖率上的表现"><a href="#实验2-1：DeepXplore在神经元覆盖率上的表现" class="headerlink" title="实验2-1：DeepXplore在神经元覆盖率上的表现"></a>实验2-1：DeepXplore在神经元覆盖率上的表现</h4><ul>
<li><p>实验方法：使用三种方法（DeepXplore、对抗样本FGSM、原测试集随机选择）生成相同数量（测试集的1%）的输入，比较神经元覆盖率</p>
</li>
<li><p>实验结果：DeepXplore能达到更高的覆盖率，且随着$t$的提升，覆盖率逐渐降低。</p>
</li>
</ul>
<p><img src="/2020/08/19/DeepXplore/ex2-1.png" alt="ex2-1"></p>
<h4 id="实验2-2：运行时间"><a href="#实验2-2：运行时间" class="headerlink" title="实验2-2：运行时间"></a>实验2-2：运行时间</h4><ul>
<li><p>实验方法：不同数据集和模型生成100%覆盖率输入所需时间及相应的生成数量。<font color="red">所有图像分类模型不考虑全连接层的覆盖（作者解释因为全连接层有的神经元非常难覆盖到，但全连接层的覆盖情况应该意义更大？）</font></p>
</li>
<li><p>实验结果：DeepXplore生成高覆盖率的输入效率非常高。</p>
</li>
</ul>
<p><img src="/2020/08/19/DeepXplore/ex2-2.png" alt="ex2-2" style="zoom: 67%;"></p>
<h4 id="实验2-3：不同参数设置的影响"><a href="#实验2-3：不同参数设置的影响" class="headerlink" title="实验2-3：不同参数设置的影响"></a>实验2-3：不同参数设置的影响</h4><ul>
<li>实验方法：改变参数$s$、$\lambda_1$、$\lambda_2$，比较<font color="red">找到第一个导致预测差异的输入平均运行时间（这个指标是否足够适合评价参数？）</font></li>
<li>实验结果</li>
</ul>
<p><img src="/2020/08/19/DeepXplore/ex2-3.png" alt="ex2-3" style="zoom:67%;"></p>
<p><img src="/2020/08/19/DeepXplore/ex2-4.png" alt="ex2-4" style="zoom:60%;"></p>
<h4 id="实验2-4：当多个DNN决策边界相似时DeepXplore的效果"><a href="#实验2-4：当多个DNN决策边界相似时DeepXplore的效果" class="headerlink" title="实验2-4：当多个DNN决策边界相似时DeepXplore的效果"></a>实验2-4：当多个DNN决策边界相似时DeepXplore的效果</h4><ul>
<li>实验方法：<ul>
<li>对照组：MNIST训练集（60000个样本）和LeNet-1模型，10个epoch</li>
<li>实验组：改变①训练集样本个数，②DNN卷积层模型filter个数，③训练epoch数</li>
<li>设置初始种子数为100，对比发现生成第一个使得实验组DNN和对照组DNN预测差异样本的平均迭代次数</li>
</ul>
</li>
<li>实验结果：DeepXplore从非常相似的DNN中也能发现错误样本（除了第一行diff为1时），越相似，迭代轮数越多。</li>
</ul>
<p><img src="/2020/08/19/DeepXplore/ex2-5.png" alt="ex2-5" style="zoom:67%;"></p>
<h3 id="实验3：使用DeepXplore提升DNN"><a href="#实验3：使用DeepXplore提升DNN" class="headerlink" title="实验3：使用DeepXplore提升DNN"></a>实验3：使用DeepXplore提升DNN</h3><h4 id="实验3-1：使用生成样本扩大训练集，重新训练DNN"><a href="#实验3-1：使用生成样本扩大训练集，重新训练DNN" class="headerlink" title="实验3-1：使用生成样本扩大训练集，重新训练DNN"></a>实验3-1：使用生成样本扩大训练集，重新训练DNN</h4><ul>
<li>与对抗样本训练不同的是：不需标注（采取投票形式）</li>
<li>实验方法：重新训练MNIST数据集的三个模型5个epoch，增加100张DeepXplore生成的错误图片，与对抗样本和随机从测试集选择样本比较准确率。<font color="red">（测试样本是什么？多个DNN从何而来？）</font></li>
<li>实验结果：DeepXplore平均提升准确率1%-3%</li>
</ul>
<p><img src="/2020/08/19/DeepXplore/ex3-1.png" alt="ex3-1" style="zoom:85%;"></p>
<h4 id="实验3-2：检测被污染的训练样本"><a href="#实验3-2：检测被污染的训练样本" class="headerlink" title="实验3-2：检测被污染的训练样本"></a>实验3-2：检测被污染的训练样本</h4><ul>
<li>实验过程：用两个MNIST LeNet-5模型，一个正常训练，另一个类别9的样本中30%被故意标记成了类别1。使用DeepXplore生成被错误预测成9或1的样本，在训练集中找和错误样本结构相似的样本。能识别出95.6%的污染样本。<font color="red">（写得很简略）</font></li>
</ul>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>DNN测试</tag>
        <tag>测试输入生成</tag>
        <tag>测试标准</tag>
        <tag>差分测试</tag>
      </tags>
  </entry>
</search>
