<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>【论文笔记】DeepConcolic</title>
    <url>/2020/08/19/DeepConcolic/</url>
    <content><![CDATA[<p>原文：Concolic Testing for Deep Neural Networks （ASE’18) <a id="more"></a></p>
<p>代码地址：<a href="https://github.com/TrustAI/DeepConcolic">https://github.com/TrustAI/DeepConcolic</a> （利普希茨覆盖测试部分用MATLAB写的）</p>
<h2 id="概括"><a href="#概括" class="headerlink" title="概括"></a>概括</h2><ul>
<li>提出了第一种DNN的Concolic测试方法。通过具体执行获得激活模式，通过反转神经元的值，优化得到变换后的输入（类似约束求解器）。使测试集达到高覆盖率。</li>
<li><p>提出利普希茨常数覆盖标准。</p>
</li>
<li><p>与其他方法比较：</p>
</li>
</ul>
<p><img src="/2020/08/19/DeepConcolic/compare.png" alt="compare"></p>
<font color="red">（DeepTest中的Jaccard距离并不是用来约束图片距离的，只是比较激活神经元的差异）</font>

<h2 id="形式化定义"><a href="#形式化定义" class="headerlink" title="形式化定义"></a>形式化定义</h2><h3 id="激活模式"><a href="#激活模式" class="headerlink" title="激活模式"></a>激活模式</h3><p>$ap[t]_{k,l} \in \{true,false\}$ 表示输入$t$的第$k$层第$l$个神经元是否被$ReLU$函数激活。</p>
<h3 id="覆盖要求"><a href="#覆盖要求" class="headerlink" title="覆盖要求"></a>覆盖要求</h3><p>略，公式较多但比较好理解，逻辑形式表达覆盖标准。</p>
<h3 id="覆盖要求的可满足性"><a href="#覆盖要求的可满足性" class="headerlink" title="覆盖要求的可满足性"></a>覆盖要求的可满足性</h3><p>给定一组测试用例$T$和覆盖要求$r$  ，$T \vDash r$表示测试用例满足了覆盖要求。</p>
<h3 id="覆盖要求的复杂度"><a href="#覆盖要求的复杂度" class="headerlink" title="覆盖要求的复杂度"></a>覆盖要求的复杂度</h3><p>检查$T \vDash r$需要能在多项式时间内完成。</p>
<h3 id="覆盖率"><a href="#覆盖率" class="headerlink" title="覆盖率"></a>覆盖率</h3><p>给定一个覆盖要求的集合$R$,测试用例集$T$可满足要求的数量所占比例即覆盖率。</p>
<h2 id="特定覆盖要求介绍"><a href="#特定覆盖要求介绍" class="headerlink" title="特定覆盖要求介绍"></a>特定覆盖要求介绍</h2><p>本节用上面的方法形式化定义了目前学术界已有的一些覆盖标准。</p>
<h3 id="利普希茨连续条件（Lipschitz-Continuity）"><a href="#利普希茨连续条件（Lipschitz-Continuity）" class="headerlink" title="利普希茨连续条件（Lipschitz Continuity）"></a>利普希茨连续条件（Lipschitz Continuity）</h3><p>对一个神经网络$N$，若存在$c\geq0$，使得对输入样本集合$D_{L1}$中的任意两个样本$x_1$、$x_2$，满足：</p>
<script type="math/tex; mode=display">\parallel v[x_1]_1-v[x_2]_1 \parallel \leq c \cdot \parallel x_1-x_2 \parallel</script><p>其中$v[x]_1$表示<font color="red">输入层</font>神经元的激活向量（？），$c$为利普希茨常数。满足条件的最小的$c$称为最佳利普希茨常数$c_{best}$。</p>
<p>利普希茨覆盖：是一组覆盖要求的集合，要求体现了给定输入子空间中的任意两个输入$x_1$、$x_2$满足上述利普希茨连续条件的情况</p>
<h3 id="神经元覆盖率（NC）"><a href="#神经元覆盖率（NC）" class="headerlink" title="神经元覆盖率（NC）"></a>神经元覆盖率（NC）</h3><p>DeepXplore中定义的神经元覆盖率，形式化表示为一组覆盖标准：</p>
<p>$\{\exists x.ap[x]_{k,i}=true|2\leq k \leq K-1,1 \leq i \leq s_k\}$</p>
<p>即对每个神经元提出一个覆盖要求——存在输入x能将其激活。</p>
<h3 id="MC-DC覆盖率（SS-coverage）"><a href="#MC-DC覆盖率（SS-coverage）" class="headerlink" title="MC/DC覆盖率（SS coverage）"></a>MC/DC覆盖率（SS coverage）</h3><p>DeepCover提出，</p>
<h3 id="神经元边缘覆盖率（NBC）"><a href="#神经元边缘覆盖率（NBC）" class="headerlink" title="神经元边缘覆盖率（NBC）"></a>神经元边缘覆盖率（NBC）</h3><p>DeepGauge中提出，</p>
<h2 id="本文方法"><a href="#本文方法" class="headerlink" title="本文方法"></a>本文方法</h2><h3 id="算法概览"><a href="#算法概览" class="headerlink" title="算法概览"></a>算法概览</h3><p><img src="/2020/08/19/DeepConcolic/overview.png" alt="overview" style="zoom:80%;"></p>
<p><img src="/2020/08/19/DeepConcolic/算法.png" alt="算法" style="zoom:60%;"></p>
<ul>
<li>输入<ul>
<li>一个DNN $N$</li>
<li>一个输入样本$t_0$</li>
<li>一组覆盖要求$R$</li>
<li>启发式$\delta$：<font color="red">与选择的覆盖要求有关，使得第7行能尽可能找到一组容易满足的要求</font></li>
</ul>
</li>
<li>输出：<ul>
<li>一组测试样本$T$，最初只包含$t_0$</li>
</ul>
</li>
<li><p>validity_check函数：检查$t’$是否有效</p>
</li>
<li><p>当$R$中所有要求被满足或不能满足$R$中的其他要求时算法停止</p>
</li>
</ul>
<h3 id="要求评估（requirement-evaluation函数，具体执行部分"><a href="#要求评估（requirement-evaluation函数，具体执行部分" class="headerlink" title="要求评估（requirement_evaluation函数，具体执行部分)"></a>要求评估（requirement_evaluation函数，具体执行部分)</h3><ul>
<li><p>寻找一组$(t,r)$，使得$t$变换成$t’$后最有可能满足要求$r$。</p>
</li>
<li><p>定义$arg max_x a:e$ ：满足布尔表达式$e$的所有样本里，使得算数表达式$a$最大的$x$</p>
</li>
<li><p>启发式：略，得到使得覆盖要求表达式（即前面的四种覆盖率）值取到最大的样本</p>
<ul>
<li>利普希茨连续</li>
<li>NC</li>
<li>SSC</li>
<li>NBC</li>
</ul>
</li>
</ul>
<h3 id="符号分析（symbolic-analysis函数）"><a href="#符号分析（symbolic-analysis函数）" class="headerlink" title="符号分析（symbolic_analysis函数）"></a>符号分析（symbolic_analysis函数）</h3><p>根据$(t,r)$变换$t$生成$t’$，有三种方法：</p>
<h4 id="1、利用线性编程进行符号分析"><a href="#1、利用线性编程进行符号分析" class="headerlink" title="1、利用线性编程进行符号分析"></a>1、利用线性编程进行符号分析</h4><p>将DNN实例$N(x)$映射到可以使用线性编程(LP)建模的激活模式$ap[x]$，并根据不同覆盖准则定义新的激活模式$ap’[x]$:</p>
<ul>
<li>NC：反转某神经元$n_{k,i}$的值，保持第$k$层之前的层的输出不变，因为该神经元只受之前层的影响。之后层的输出不用管。</li>
<li>SSC：反转$n_{k+1,j}$和$n_{k,i}$</li>
<li>NBC：目标使得神经元$n_{k,i}$的激活值超过其上界或低于其下界</li>
</ul>
<p>LP模型将对$ap’[x]$进行编码并求解满足要求$r$的输入$t’$</p>
<h4 id="2、基于全局优化的符号分析"><a href="#2、基于全局优化的符号分析" class="headerlink" title="2、基于全局优化的符号分析"></a>2、基于全局优化的符号分析</h4><p>基于全局优化算法达到上述目标生成$t’$</p>
<h4 id="3、Lipschitz测试用例生成"><a href="#3、Lipschitz测试用例生成" class="headerlink" title="3、Lipschitz测试用例生成"></a>3、Lipschitz测试用例生成</h4><p>本文提出了一种新颖的交替式罗盘搜索方案（略）</p>
<h3 id="测试预言（约束）"><a href="#测试预言（约束）" class="headerlink" title="测试预言（约束）"></a>测试预言（约束）</h3><p>给定实数$b$，如果测试用例$t’ \in T$满足：</p>
<script type="math/tex; mode=display">\parallel t-t' \parallel \leq b</script><p>则称$t’$为有效的。若$t$与$t’$的预测结果一致，则称DNN通过了测试预言。</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul>
<li>时间限制：12h</li>
<li>所有覆盖结果均运行10次以上取平均</li>
</ul>
<h3 id="实验1：与DeepXplore对比"><a href="#实验1：与DeepXplore对比" class="headerlink" title="实验1：与DeepXplore对比"></a>实验1：与DeepXplore对比</h3><ul>
<li><p>数据集：MNIST、CIFAR-10</p>
</li>
<li><p>实验方法</p>
<ul>
<li>从随机采样的初始种子集合开始</li>
<li>DeepXplore要求多个模型差分测试：采用目标测试的DNN模型+DeepXplore论文里的2个模型</li>
<li>比较二者达到的覆盖率</li>
</ul>
</li>
<li><p>实验结果</p>
<p><img src="/2020/08/19/DeepConcolic/ex1.png" alt="ex1" style="zoom:70%;"></p>
<ul>
<li>DeepConcolic能达到比DeepXplore更高的覆盖率</li>
<li>但DeepXplore更快，几秒内运行结束<font color="red">（没有说DeepConcolic的运行时间）</font></li>
<li>生成的图像：<font color="red">(几乎完全反相也符合约束？)</font></li>
</ul>
<p><img src="/2020/08/19/DeepConcolic/ex1-2.png" alt="ex1-2" style="zoom:67%;"></p>
</li>
</ul>
<h3 id="实验2：比较NC-SCC和NBC"><a href="#实验2：比较NC-SCC和NBC" class="headerlink" title="实验2：比较NC, SCC和NBC"></a>实验2：比较NC, SCC和NBC</h3><ul>
<li><p>实验方法</p>
<ul>
<li>NC：从一张初始种子开始</li>
<li>SCC和NBC：初始集合包含1000张图片，且仅测试一部分神经元<font color="red">（和NC差别很大）</font></li>
<li>设置$L _\infty$的距离上界为0.3，$L_0$的距离上界为100个像素</li>
</ul>
</li>
<li><p>实验结果</p>
<p><img src="/2020/08/19/DeepConcolic/MyBlog\source\_posts\DeepConcolic\ex2-1.png" alt="ex2-1" style="zoom:70%;"></p>
<p><img src="/2020/08/19/DeepConcolic/ex2-3.png" alt="ex2-3"></p>
<ul>
<li><p>使用全局优化进行符号分析的开销太高。因此，具有$L_0$范数的SSC结果被排除在外。<font color="red">(?右图没有蓝色条形)</font></p>
</li>
<li><p>总体而言，DeepConcolic实现了高覆盖率，并使用健壮性检查检测到大量的对抗性示例。然而，NBC的覆盖范围是有限的</p>
</li>
<li><p>concolic测试可以发现距离极小的对抗样本：如1255≈0.0039（$L_{\infty}$范数），1像素（$L_0$范数）</p>
</li>
<li><p>对抗样本的平均距离：(对于同一网络，当距离度量改变时，使用NC发现的对抗性示例的数量可能会有很大变化。在设计DNN的覆盖标准时，需要使用各种距离度量来检查它们。)</p>
<p><img src="/2020/08/19/DeepConcolic/ex2-2.png" alt="ex2-2" style="zoom:67%;"></p>
</li>
</ul>
</li>
</ul>
<h3 id="实验3：利普希茨常数检验结果"><a href="#实验3：利普希茨常数检验结果" class="headerlink" title="实验3：利普希茨常数检验结果"></a>实验3：利普希茨常数检验结果</h3><p><img src="/2020/08/19/DeepConcolic/ex3-1.png" alt="ex3-1" style="zoom:80%;"></p>
<ul>
<li>我们通过随机测试生成的方式产生了100万个测试对，但最大Lipschitz转换率只达到了3.23，并且大多数测试对都在[0.01，2]的范围内。另一方面，我们的Concolic方法可以覆盖[0.01，10.38]的Lipschitz范围，其中大多数情况位于[3.5，10]，而随机测试生成很难覆盖这一范围。</li>
<li>目标：覆盖较大Lipschitz常数范围。如对于自动驾驶汽车等安全关键应用，Lipschitz常数较大的DNN本质上表明它更容易受到对手的扰动。因此，可以覆盖较大Lipschitz常数的测试方法为训练的DNN提供了有用的鲁棒性指标。我们认为，对于DNNs的安全测试，Lipschitz常数覆盖的Concolic测试方法可以补充现有的方法来实现更好的覆盖。</li>
</ul>
<h2 id="可控制参数和变量总结"><a href="#可控制参数和变量总结" class="headerlink" title="可控制参数和变量总结"></a>可控制参数和变量总结</h2><ul>
<li>初始样本集合</li>
<li>覆盖标准：利普希茨常数覆盖、NC、NBC、SSC</li>
<li>变换约束条件（$L_\infty$、$L_0$及其参数）</li>
<li>测试的神经元（全部还是部分）</li>
</ul>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>DNN测试</tag>
      </tags>
  </entry>
</search>
